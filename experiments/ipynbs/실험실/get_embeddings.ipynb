{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "sys.path.append(\"../../../\")\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import copy\n",
        "import torch\n",
        "from datetime import datetime\n",
        "from src.utils.helper import Config, color_print\n",
        "from src.utils.load import load_model, load_data, save_checkpoint, load_checkpoint\n",
        "from src.models.evaluate import evaluate_model, get_sparsity, get_similarity\n",
        "from src.utils.sampling import SamplingDataset\n",
        "from src.pruning.prune_head import head_importance_prunning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# name = \"bert-tiny-yahoo\"\n",
        "name = \"bert-4-128-yahoo\"\n",
        "device = torch.device(\"cuda:0\")\n",
        "checkpoint = None\n",
        "batch_size = 16\n",
        "num_workers = 4\n",
        "num_samples = 128\n",
        "ci_ratio = 0.3\n",
        "seed = 44"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "config = Config(name, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading the model.\n",
            "{'architectures': 'bert',\n",
            " 'dataset_name': 'YahooAnswersTopics',\n",
            " 'model_name': 'models/bert-4-128-yahoo',\n",
            " 'num_labels': 10,\n",
            " 'tokenizer_name': 'fabriceyhc/bert-base-uncased-yahoo_answers_topics'}\n",
            "The model models/bert-4-128-yahoo is loaded.\n"
          ]
        }
      ],
      "source": [
        "model = load_model(config=config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading cached dataset YahooAnswersTopics.\n",
            "train.pkl is loaded from cache.\n",
            "valid.pkl is loaded from cache.\n",
            "test.pkl is loaded from cache.\n",
            "The dataset YahooAnswersTopics is loaded\n",
            "{'config_name': 'yahoo_answers_topics',\n",
            " 'features': {'first_column': 'question_title', 'second_column': 'topic'},\n",
            " 'path': 'yahoo_answers_topics'}\n"
          ]
        }
      ],
      "source": [
        "train_dataloader, valid_dataloader, test_dataloader = load_data(\n",
        "    config,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=num_workers,\n",
        "    do_cache=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "positive_samples = SamplingDataset(\n",
        "    train_dataloader,\n",
        "    config,\n",
        "    0,\n",
        "    num_samples,\n",
        "    True,\n",
        "    4,\n",
        "    resample=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "negative_samples = SamplingDataset(\n",
        "    train_dataloader,\n",
        "    config,\n",
        "    0,\n",
        "    num_samples,\n",
        "    False,\n",
        "    4,\n",
        "    resample=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from scipy.stats import norm\n",
        "from typing import *\n",
        "from torch import Tensor\n",
        "from torch.nn import Module\n",
        "import torch.nn.functional as F\n",
        "from functools import partial\n",
        "from src.utils.sampling import SamplingDataset\n",
        "from src.pruning.propagate import propagate\n",
        "from src.utils.helper import Config\n",
        "import gc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calc_coefficient(combined_dataloader, dim=0):\n",
        "    embeddings = combined_dataloader[0][\"embeddings\"]\n",
        "\n",
        "    batch_size = embeddings.shape[0] // 2\n",
        "    concern_inputs, non_concern_inputs = (\n",
        "        embeddings[:batch_size],\n",
        "        embeddings[batch_size:],\n",
        "    )\n",
        "\n",
        "    calc_norm = lambda tensors, dim: torch.norm(\n",
        "        tensors.reshape((-1, tensors.shape[-1])), dim=dim\n",
        "    )\n",
        "\n",
        "    if dim == 0:\n",
        "        new_shape = (-1, 1)\n",
        "    else:\n",
        "        new_shape = (1, -1)\n",
        "\n",
        "    concern_norm = calc_norm(concern_inputs, dim=0).reshape(new_shape)\n",
        "    non_concern_norm = calc_norm(non_concern_inputs, dim=0).reshape(new_shape)\n",
        "\n",
        "    cosine_similarity = F.cosine_similarity(\n",
        "        concern_inputs.reshape((-1, concern_inputs.shape[-1])),\n",
        "        non_concern_inputs.reshape((-1, non_concern_inputs.shape[-1])),\n",
        "        dim=0,\n",
        "    ).reshape(new_shape)\n",
        "\n",
        "    sine_similarity = torch.sign(cosine_similarity) * torch.sqrt(\n",
        "        1 - cosine_similarity**2\n",
        "    )\n",
        "    euclidean_distance = torch.sqrt(concern_norm**2 + non_concern_norm**2)\n",
        "    coefficient = (\n",
        "        concern_norm\n",
        "        + sine_similarity\n",
        "        * torch.abs(concern_norm + non_concern_norm)\n",
        "        / euclidean_distance\n",
        "    )\n",
        "    return coefficient"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def find_layers(\n",
        "    model: Module,\n",
        "    layer_types: Optional[List[Type[Module]]] = None,\n",
        "    include_layers: Optional[List[str]] = None,\n",
        "    exclude_layers: Optional[List[str]] = None,\n",
        "    prefix: str = \"\",\n",
        ") -> Dict[str, Module]:\n",
        "    if layer_types is None:\n",
        "        layer_types = [nn.Linear]\n",
        "    if include_layers is None:\n",
        "        include_layers = []\n",
        "    if exclude_layers is None:\n",
        "        exclude_layers = []\n",
        "    layers_dict: Dict[str, Module] = {}\n",
        "\n",
        "    def recursive_find(module: Module, prefix: str) -> None:\n",
        "        for name, layer in module.named_children():\n",
        "            layer_name = f\"{prefix}.{name}\" if prefix else name\n",
        "            if any(exclude in layer_name for exclude in exclude_layers):\n",
        "                continue\n",
        "            if include_layers and not any(\n",
        "                include in layer_name for include in include_layers\n",
        "            ):\n",
        "                if not any(isinstance(layer, t) for t in layer_types):\n",
        "                    recursive_find(layer, layer_name)\n",
        "                continue\n",
        "            if isinstance(layer, tuple(layer_types)):\n",
        "                layers_dict[layer_name] = layer\n",
        "            else:\n",
        "                recursive_find(layer, layer_name)\n",
        "\n",
        "    recursive_find(model, prefix)\n",
        "\n",
        "    return layers_dict\n",
        "\n",
        "\n",
        "def get_hook(method):\n",
        "    def hook(module, input, output):\n",
        "        method(module, input, output)\n",
        "\n",
        "    return hook\n",
        "\n",
        "\n",
        "def get_embeddings(model, dataloader):\n",
        "    embeddings_list = {\"embeddings\": [], \"labels\": [], \"attention_mask\": []}\n",
        "\n",
        "    for batch in dataloader:\n",
        "        input_ids = batch[\"input_ids\"]\n",
        "        labels = batch[\"labels\"]\n",
        "        attention_mask = batch[\"attention_mask\"]\n",
        "        with torch.no_grad():\n",
        "            input_embeddings = model.get_input_embeddings()(input_ids)\n",
        "        embeddings_list[\"embeddings\"].append(input_embeddings)\n",
        "        embeddings_list[\"labels\"].append(labels)\n",
        "        embeddings_list[\"attention_mask\"].append(attention_mask)\n",
        "        from src.utils.data_class import CustomEmbeddingDataset\n",
        "    return CustomEmbeddingDataset(embeddings_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Pruner:\n",
        "    def __init__(self, layers, ratio: float, method=\"unstructed\") -> None:\n",
        "        self.layers = layers\n",
        "        self.ratio = ratio\n",
        "        self.coefficient = None\n",
        "        self.method = method\n",
        "        self.pruning_mask = {}\n",
        "        self.pruning_indices = {}\n",
        "\n",
        "    def ci(self, layer, inputs, outputs):\n",
        "        current_weight = layer.weight.data.clone()\n",
        "\n",
        "        importance_score = torch.abs(current_weight) * torch.abs(self.coefficient)\n",
        "\n",
        "        indices_vector = None\n",
        "        if self.method == \"unstructed\":\n",
        "            sort_res = torch.sort(importance_score, dim=-1, stable=True)\n",
        "            num_prune = int(current_weight.shape[1] * self.ratio)\n",
        "            indices_matrix = sort_res[1][:, :num_prune]\n",
        "            W_mask = (torch.zeros_like(importance_score) == 1).scatter_(\n",
        "                1, indices_matrix, True\n",
        "            )\n",
        "        elif self.method == \"structed\":\n",
        "            importance_vector = torch.norm(importance_score, dim=1)\n",
        "            num_prune = int(importance_vector.shape[0] * self.ratio)\n",
        "            sort_res = torch.sort(importance_vector)\n",
        "            indices_vector = sort_res[1][:num_prune]\n",
        "            W_mask = (torch.zeros_like(importance_vector) == 1).scatter_(\n",
        "                0, indices_vector, True\n",
        "            )\n",
        "        else:\n",
        "            raise NotImplementedError(f\"{self.method} is not implemented\")\n",
        "\n",
        "        if self.method == \"unstructed\":\n",
        "            sorted_indices_matrix = torch.sort(indices_matrix, dim=1)[0]\n",
        "            indices = sorted_indices_matrix\n",
        "\n",
        "        elif self.method == \"structed\":\n",
        "            sorted_indices_vector = torch.sort(indices_vector)[0]\n",
        "            indices = sorted_indices_vector\n",
        "        else:\n",
        "            raise NotImplementedError(f\"The method {self.method} is not implemented\")\n",
        "\n",
        "        layer_id = id(layer)\n",
        "        layer_name = [key for key, val in self.layers.items() if id(val) == layer_id][0]\n",
        "        self.pruning_mask[layer_name] = W_mask\n",
        "        self.pruning_indices[layer_name] = indices\n",
        "\n",
        "    @staticmethod\n",
        "    def apply(layer, method, axis, mask, keepdim):\n",
        "        current_weight = layer.weight.data.clone()\n",
        "        current_weight = current_weight * mask\n",
        "\n",
        "        if not keepdim:\n",
        "            if method == \"structed\":\n",
        "                if axis == 0:\n",
        "                    zero_rows = (current_weight == 0).all(dim=1)\n",
        "                    current_weight = current_weight[~zero_rows]\n",
        "\n",
        "                    if layer.bias is not None:\n",
        "                        current_bias = layer.bias.data.clone()\n",
        "                        layer.bias.data = current_bias[~zero_rows]\n",
        "                elif axis == 1:\n",
        "                    zero_cols = (current_weight == 0).all(dim=0)\n",
        "                    current_weight = current_weight[:, ~zero_cols]\n",
        "        layer.in_features = current_weight.shape[1]\n",
        "        layer.out_features = current_weight.shape[0]\n",
        "        layer.weight.data = current_weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "def prune_concern_identification(\n",
        "    model: Module,\n",
        "    config: Config,\n",
        "    dominant_concern: SamplingDataset,\n",
        "    non_dominant_concern: SamplingDataset,\n",
        "    sparsity_ratio: float = 0.6,\n",
        "    include_layers: Optional[List[str]] = None,\n",
        "    exclude_layers: Optional[List[str]] = None,\n",
        "    method=\"unstructed\",\n",
        "    keep_dim=True,\n",
        ") -> None:\n",
        "    layers = find_layers(\n",
        "        model, include_layers=include_layers, exclude_layers=exclude_layers\n",
        "    )\n",
        "    handle_list = []\n",
        "    pruner = Pruner(layers, ratio=sparsity_ratio, method=method)\n",
        "\n",
        "    for name, layer in layers.items():\n",
        "        if method == \"structed\":\n",
        "            if \"intermediate\" in name:\n",
        "                handle = layer.register_forward_hook(pruner.ci)\n",
        "                handle_list.append(handle)\n",
        "        else:\n",
        "            handle = layer.register_forward_hook(pruner.ci)\n",
        "            handle_list.append(handle)\n",
        "\n",
        "    pos_embeddings = get_embeddings(model, dominant_concern)\n",
        "    neg_embeddings = get_embeddings(model, non_dominant_concern)\n",
        "    dominant_batches = list(pos_embeddings)\n",
        "    non_dominant_batches = list(neg_embeddings)\n",
        "    combined_batches = {}\n",
        "    keys = dominant_batches[0].keys()\n",
        "    for key in keys:\n",
        "        combined_batches[key] = torch.cat(\n",
        "            [batch[key] for batch in dominant_batches + non_dominant_batches]\n",
        "        )\n",
        "\n",
        "    combined_dataloader = [combined_batches]\n",
        "    pruner.coefficient = calc_coefficient(combined_dataloader, dim=1).to(config.device)\n",
        "    propagate(model, combined_dataloader, config)\n",
        "\n",
        "    for handle in handle_list:\n",
        "        handle.remove()\n",
        "\n",
        "    intermediate_mask = None\n",
        "    for name, layer in layers.items():\n",
        "        print(name)\n",
        "        if method == \"structed\":\n",
        "            if \"intermediate\" in name:\n",
        "                current_mask = pruner.pruning_mask[name].to(\"cpu\")\n",
        "                intermediate_mask = current_mask\n",
        "                current_mask = current_mask.unsqueeze(dim=1).expand(\n",
        "                    -1, layer.weight.shape[1]\n",
        "                )\n",
        "                Pruner.apply(\n",
        "                    layer,\n",
        "                    method=\"structed\",\n",
        "                    axis=0,\n",
        "                    mask=current_mask,\n",
        "                    keepdim=keep_dim,\n",
        "                )\n",
        "            elif \"output\" in name:\n",
        "                current_mask = intermediate_mask.unsqueeze(dim=0).expand(\n",
        "                    layer.weight.shape[0], -1\n",
        "                )\n",
        "                Pruner.apply(\n",
        "                    layer,\n",
        "                    method=\"structed\",\n",
        "                    axis=1,\n",
        "                    mask=current_mask,\n",
        "                    keepdim=keep_dim,\n",
        "                )\n",
        "        elif method == \"unstructed\":\n",
        "            current_mask = pruner.pruning_mask[name][0].to(\"cpu\")\n",
        "            Pruner.apply(\n",
        "                layer, method=\"unstructed\", axis=0, mask=current_mask, keepdim=keep_dim\n",
        "            )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bert.encoder.layer.0.intermediate.dense\n"
          ]
        },
        {
          "ename": "IndexError",
          "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[14], line 35\u001b[0m\n\u001b[1;32m     23\u001b[0m all_samples \u001b[38;5;241m=\u001b[39m SamplingDataset(\n\u001b[1;32m     24\u001b[0m     train_dataloader,\n\u001b[1;32m     25\u001b[0m     config,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     30\u001b[0m     resample\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     31\u001b[0m )\n\u001b[1;32m     33\u001b[0m module \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(model)\n\u001b[0;32m---> 35\u001b[0m \u001b[43mprune_concern_identification\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpositive_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnegative_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_layers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mintermediate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexclude_layers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mattention\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43msparsity_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstructed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluate the pruned model \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconcern\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     48\u001b[0m result \u001b[38;5;241m=\u001b[39m evaluate_model(module, config, test_dataloader)\n",
            "Cell \u001b[0;32mIn[13], line 52\u001b[0m, in \u001b[0;36mprune_concern_identification\u001b[0;34m(model, config, dominant_concern, non_dominant_concern, sparsity_ratio, include_layers, exclude_layers, method, keep_dim)\u001b[0m\n\u001b[1;32m     50\u001b[0m     current_mask \u001b[38;5;241m=\u001b[39m pruner\u001b[38;5;241m.\u001b[39mpruning_mask[name][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     51\u001b[0m     intermediate_mask \u001b[38;5;241m=\u001b[39m current_mask\n\u001b[0;32m---> 52\u001b[0m     current_mask \u001b[38;5;241m=\u001b[39m \u001b[43mcurrent_mask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mexpand(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, layer\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     53\u001b[0m     Pruner\u001b[38;5;241m.\u001b[39mapply(layer, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstructed\u001b[39m\u001b[38;5;124m\"\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, mask\u001b[38;5;241m=\u001b[39mcurrent_mask, keepdim\u001b[38;5;241m=\u001b[39mkeep_dim)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m name:\n",
            "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
          ]
        }
      ],
      "source": [
        "result_list = []\n",
        "\n",
        "for concern in range(config.num_labels):\n",
        "    config.init_seed()\n",
        "    positive_samples = SamplingDataset(\n",
        "        train_dataloader,\n",
        "        config,\n",
        "        concern,\n",
        "        num_samples,\n",
        "        True,\n",
        "        4,\n",
        "        resample=False,\n",
        "    )\n",
        "    negative_samples = SamplingDataset(\n",
        "        train_dataloader,\n",
        "        config,\n",
        "        concern,\n",
        "        num_samples,\n",
        "        False,\n",
        "        4,\n",
        "        resample=False,\n",
        "    )\n",
        "    all_samples = SamplingDataset(\n",
        "        train_dataloader,\n",
        "        config,\n",
        "        200,\n",
        "        num_samples,\n",
        "        False,\n",
        "        4,\n",
        "        resample=False,\n",
        "    )\n",
        "\n",
        "    module = copy.deepcopy(model)\n",
        "\n",
        "    prune_concern_identification(\n",
        "        module,\n",
        "        config,\n",
        "        positive_samples,\n",
        "        negative_samples,\n",
        "        include_layers=[\"intermediate\", \"output\"],\n",
        "        exclude_layers=[\"attention\"],\n",
        "        sparsity_ratio=0.5,\n",
        "        keep_dim=True,\n",
        "        method=\"structed\",\n",
        "    )\n",
        "\n",
        "    print(f\"Evaluate the pruned model {concern}\")\n",
        "    result = evaluate_model(module, config, test_dataloader, verbose=True)\n",
        "    result_list.append(result)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.utils.helper import report_to_df, append_nth_row\n",
        "\n",
        "df_list = [report_to_df(df) for df in result_list]\n",
        "new_df = append_nth_row(df_list)\n",
        "new_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "decomposetransformer-UESb9BbT-py3.12",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}