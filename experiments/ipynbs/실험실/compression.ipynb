{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "slice by rows and columns "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "sys.path.append(\"../../../\")\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import copy\n",
        "import torch\n",
        "from datetime import datetime\n",
        "from src.utils.helper import Config, color_print\n",
        "from src.utils.load import load_model, load_data, save_checkpoint, load_checkpoint\n",
        "from src.models.evaluate import evaluate_model, get_sparsity, get_similarity\n",
        "from src.utils.sampling import SamplingDataset\n",
        "from src.pruning.prune_head import head_importance_prunning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "name = \"bert-4-128-yahoo\"\n",
        "device = torch.device(\"cuda:0\")\n",
        "checkpoint = None\n",
        "batch_size = 16\n",
        "num_workers = 4\n",
        "num_samples = 128\n",
        "ci_ratio = 0.3\n",
        "seed = 44"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "config = Config(name, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'architectures': 'bert',\n",
            " 'dataset_name': 'YahooAnswersTopics',\n",
            " 'model_name': 'models/bert-4-128-yahoo',\n",
            " 'num_labels': 10,\n",
            " 'tokenizer_name': 'fabriceyhc/bert-base-uncased-yahoo_answers_topics'}\n"
          ]
        }
      ],
      "source": [
        "config.model_summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading the model.\n",
            "{'architectures': 'bert',\n",
            " 'dataset_name': 'YahooAnswersTopics',\n",
            " 'model_name': 'models/bert-4-128-yahoo',\n",
            " 'num_labels': 10,\n",
            " 'tokenizer_name': 'fabriceyhc/bert-base-uncased-yahoo_answers_topics'}\n",
            "The model models/bert-4-128-yahoo is loaded.\n"
          ]
        }
      ],
      "source": [
        "model = load_model(config=config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading cached dataset YahooAnswersTopics.\n",
            "train.pkl is loaded from cache.\n",
            "valid.pkl is loaded from cache.\n",
            "test.pkl is loaded from cache.\n",
            "The dataset YahooAnswersTopics is loaded\n",
            "{'config_name': 'yahoo_answers_topics',\n",
            " 'features': {'first_column': 'question_title', 'second_column': 'topic'},\n",
            " 'path': 'yahoo_answers_topics'}\n"
          ]
        }
      ],
      "source": [
        "train_dataloader, valid_dataloader, test_dataloader = load_data(\n",
        "    config,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=num_workers,\n",
        "    do_cache=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_hook(method):\n",
        "    def hook(module, input, output):\n",
        "        method(module, input, output)\n",
        "\n",
        "    return hook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def find_layers(\n",
        "    model,\n",
        "    layer_types=None,\n",
        "    include_layers=None,\n",
        "    exclude_layers=None,\n",
        "    prefix: str = \"\",\n",
        "):\n",
        "    if layer_types is None:\n",
        "        layer_types = [torch.nn.Linear]\n",
        "    if include_layers is None:\n",
        "        include_layers = []\n",
        "    if exclude_layers is None:\n",
        "        exclude_layers = []\n",
        "    layers_dict = {}\n",
        "\n",
        "    def recursive_find(module, prefix: str) -> None:\n",
        "        for name, layer in module.named_children():\n",
        "            layer_name = f\"{prefix}.{name}\" if prefix else name\n",
        "            if any(exclude in layer_name for exclude in exclude_layers):\n",
        "                continue\n",
        "            if include_layers and not any(\n",
        "                include in layer_name for include in include_layers\n",
        "            ):\n",
        "                if not any(isinstance(layer, t) for t in layer_types):\n",
        "                    recursive_find(layer, layer_name)\n",
        "                continue\n",
        "            if isinstance(layer, tuple(layer_types)):\n",
        "                layers_dict[layer_name] = layer\n",
        "            else:\n",
        "                recursive_find(layer, layer_name)\n",
        "\n",
        "    recursive_find(model, prefix)\n",
        "\n",
        "    return layers_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def prune_concern_identification(\n",
        "    model,\n",
        "    model_config: Config,\n",
        "    dominant_concern: SamplingDataset,\n",
        "    non_dominant_concern: SamplingDataset,\n",
        "    sparsity_ratio: float = 0.6,\n",
        "    include_layers=None,\n",
        "    exclude_layers=None,\n",
        "    compress=False,\n",
        ") -> None:\n",
        "    layers = find_layers(\n",
        "        model, include_layers=include_layers, exclude_layers=exclude_layers\n",
        "    )\n",
        "    handle_list = []\n",
        "\n",
        "    method1 = Methods(sparsity_ratio, axis=0, compress=compress)\n",
        "    method2 = Methods(sparsity_ratio, compress=compress)\n",
        "    for name, layer in layers.items():\n",
        "        if \"intermediate\" in name:\n",
        "            handle = layer.register_forward_hook(method1.ci)\n",
        "        else:\n",
        "            handle = layer.register_forward_hook(method2.ci)\n",
        "        handle_list.append(handle)\n",
        "\n",
        "    dominant_batches = list(dominant_concern)\n",
        "    non_dominant_batches = list(non_dominant_concern)\n",
        "\n",
        "    if len(dominant_batches) != len(non_dominant_batches):\n",
        "        raise ValueError(\n",
        "            \"Batch sizes of dominant_concern and non_dominant_concern does not match.\"\n",
        "        )\n",
        "\n",
        "    combined_batches = {}\n",
        "    keys = dominant_batches[0].keys()\n",
        "\n",
        "    for key in keys:\n",
        "        combined_batches[key] = torch.cat(\n",
        "            [batch[key] for batch in dominant_batches + non_dominant_batches]\n",
        "        )\n",
        "\n",
        "    combined_dataloader = [combined_batches]\n",
        "    from src.pruning.propagate import propagate\n",
        "\n",
        "    propagate(model, combined_dataloader, model_config)\n",
        "\n",
        "    for handle in handle_list:\n",
        "        handle.remove()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Methods:\n",
        "    def __init__(self, ratio: float, axis=1, compress=False) -> None:\n",
        "        self.ratio = ratio\n",
        "        self.axis = axis\n",
        "        self.compress = compress\n",
        "\n",
        "    def ci(self, layer, inputs, outputs):\n",
        "        current_weight = layer.weight.data\n",
        "        current_bias = layer.bias.data if layer.bias is not None else None\n",
        "        X = inputs[0]\n",
        "\n",
        "        batch_size = X.shape[0] // 2\n",
        "\n",
        "        concern_inputs, non_concern_inputs = (\n",
        "            X[:batch_size],\n",
        "            X[batch_size:],\n",
        "        )  # (batch_size, seq_dim, input_dim)\n",
        "\n",
        "        calc_norm = lambda tensors, dim: torch.norm(\n",
        "            tensors.reshape((-1, tensors.shape[-1])), dim=dim\n",
        "        )\n",
        "\n",
        "        concern_norm = calc_norm(concern_inputs, dim=0).reshape((1, -1))\n",
        "        non_concern_norm = calc_norm(non_concern_inputs, dim=0).reshape((1, -1))\n",
        "\n",
        "        cosine_similarity = torch.nn.functional.cosine_similarity(\n",
        "            concern_inputs.reshape((-1, concern_inputs.shape[-1])),\n",
        "            non_concern_inputs.reshape((-1, non_concern_inputs.shape[-1])),\n",
        "            dim=0,\n",
        "        ).reshape(1, -1)\n",
        "\n",
        "        sine_similarity = torch.sqrt(1 - cosine_similarity**2)\n",
        "        distance = torch.sqrt(concern_norm**2 + non_concern_norm**2)\n",
        "        coefficient = (\n",
        "            concern_norm\n",
        "            + sine_similarity * torch.abs(concern_norm + non_concern_norm) / distance\n",
        "        )\n",
        "\n",
        "        importance_score = torch.abs(current_weight) * torch.abs(coefficient)\n",
        "\n",
        "        if self.axis == 1:\n",
        "            importance_vector = torch.mean(importance_score, axis=0)\n",
        "        else:\n",
        "            importance_vector = torch.mean(importance_score, axis=1)\n",
        "\n",
        "        sort_res = torch.sort(importance_vector, stable=True)\n",
        "        num_prune = int(importance_vector.numel() * self.ratio)\n",
        "        indices_to_prune = sort_res[1][:num_prune]\n",
        "\n",
        "        mask = torch.ones(current_weight.shape[self.axis], dtype=bool)\n",
        "        mask[indices_to_prune] = False\n",
        "        if self.axis == 1:\n",
        "            pruned_weight = current_weight[:, mask]\n",
        "\n",
        "        else:\n",
        "            pruned_weight = current_weight[mask, :]\n",
        "            pruned_bias = current_bias[mask]\n",
        "            layer.bias.data = pruned_bias\n",
        "\n",
        "        layer.weight.data = pruned_weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluate the pruned model 0\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9a0434527617401bb6182e90ad235669",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating the model:   0%|          | 0/1875 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 1.2424\n",
            "Precision: 0.6479, Recall: 0.6055, F1-Score: 0.6113\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.5415    0.4843    0.5113      2992\n",
            "           1     0.7079    0.4723    0.5666      2992\n",
            "           2     0.7242    0.5850    0.6472      3012\n",
            "           3     0.3243    0.6481    0.4323      2998\n",
            "           4     0.7303    0.7514    0.7407      2973\n",
            "           5     0.8624    0.7344    0.7933      3054\n",
            "           6     0.6908    0.3660    0.4785      3003\n",
            "           7     0.6221    0.6232    0.6227      3012\n",
            "           8     0.5645    0.7364    0.6391      2982\n",
            "           9     0.7105    0.6543    0.6812      2982\n",
            "\n",
            "    accuracy                         0.6056     30000\n",
            "   macro avg     0.6479    0.6055    0.6113     30000\n",
            "weighted avg     0.6482    0.6056    0.6115     30000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for concern in range(config.num_labels):\n",
        "    train = copy.deepcopy(train_dataloader)\n",
        "    valid = copy.deepcopy(valid_dataloader)\n",
        "    positive_samples = SamplingDataset(\n",
        "        train,\n",
        "        config,\n",
        "        concern,\n",
        "        num_samples,\n",
        "        True,\n",
        "        4,\n",
        "        resample=False,\n",
        "    )\n",
        "    negative_samples = SamplingDataset(\n",
        "        train,\n",
        "        config,\n",
        "        concern,\n",
        "        num_samples,\n",
        "        False,\n",
        "        4,\n",
        "        resample=False,\n",
        "    )\n",
        "    all_samples = SamplingDataset(\n",
        "        train,\n",
        "        config,\n",
        "        200,\n",
        "        num_samples,\n",
        "        False,\n",
        "        4,\n",
        "        resample=False,\n",
        "    )\n",
        "\n",
        "    module = copy.deepcopy(model)\n",
        "\n",
        "    prune_concern_identification(\n",
        "        module,\n",
        "        config,\n",
        "        positive_samples,\n",
        "        negative_samples,\n",
        "        include_layers=[\"intermediate\", \"output\"],\n",
        "        exclude_layers=[\"attention\"],\n",
        "        sparsity_ratio=0.5,\n",
        "        compress=True,\n",
        "    )\n",
        "\n",
        "    print(f\"Evaluate the pruned model {concern}\")\n",
        "    result = evaluate_model(module, config, test_dataloader, verbose=True)\n",
        "\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "942972d41b514474ac88733522343cd8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating the model:   0%|          | 0/1875 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 1.2240\n",
            "Precision: 0.6478, Recall: 0.6149, F1-Score: 0.6195\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.5321    0.4843    0.5071      2992\n",
            "           1     0.7005    0.4723    0.5642      2992\n",
            "           2     0.6957    0.6119    0.6511      3012\n",
            "           3     0.3443    0.6421    0.4482      2998\n",
            "           4     0.7254    0.7783    0.7509      2973\n",
            "           5     0.8403    0.7600    0.7981      3054\n",
            "           6     0.6719    0.4106    0.5097      3003\n",
            "           7     0.6185    0.6384    0.6283      3012\n",
            "           8     0.5854    0.7146    0.6436      2982\n",
            "           9     0.7637    0.6362    0.6941      2982\n",
            "\n",
            "    accuracy                         0.6150     30000\n",
            "   macro avg     0.6478    0.6149    0.6195     30000\n",
            "weighted avg     0.6481    0.6150    0.6198     30000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "result = evaluate_model(model, config, test_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_layer0_inputs(model, batch):\n",
        "    with torch.no_grad():\n",
        "        first_layer = list(model.children())[0]\n",
        "\n",
        "        embeddings = first_layer(batch)\n",
        "\n",
        "        return embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'model_adapter' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m train_dataloader:\n\u001b[0;32m----> 2\u001b[0m   inp_batch, args_batch, kwargs_batch \u001b[38;5;241m=\u001b[39m get_layer0_inputs(\u001b[43mmodel_adapter\u001b[49m, batch)\n\u001b[1;32m      3\u001b[0m   inps\u001b[38;5;241m.\u001b[39mappend(inp_batch)\n\u001b[1;32m      4\u001b[0m   args\u001b[38;5;241m.\u001b[39mappend(args_batch)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model_adapter' is not defined"
          ]
        }
      ],
      "source": [
        "for batch in train_dataloader:\n",
        "    inp_batch, args_batch, kwargs_batch = get_layer0_inputs(model_adapter, batch)\n",
        "    inps.append(inp_batch)\n",
        "    args.append(args_batch)\n",
        "    kwargs.append(kwargs_batch)\n",
        "    if apply_mask:\n",
        "        ignore_masks.append(batch[\"attention_mask\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'dict' object has no attribute 'double'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[14], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m H \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_dataloader):\n\u001b[0;32m----> 3\u001b[0m   batch \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdouble\u001b[49m()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m   H_batch \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(batch\u001b[38;5;241m.\u001b[39mmT \u001b[38;5;241m@\u001b[39m batch, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      5\u001b[0m   H \u001b[38;5;241m=\u001b[39m H_batch \u001b[38;5;28;01mif\u001b[39;00m H \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m H \u001b[38;5;241m+\u001b[39m H_batch\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'double'"
          ]
        }
      ],
      "source": [
        "H = None\n",
        "for idx, batch in enumerate(train_dataloader):\n",
        "    batch = batch.double().to(\"cuda\")\n",
        "    H_batch = torch.sum(batch.mT @ batch, dim=0)\n",
        "    H = H_batch if H is None else H + H_batch"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "decomposetransformer-UESb9BbT-py3.12",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}