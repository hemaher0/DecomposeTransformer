{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../../../\")\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch\n",
    "from datetime import datetime\n",
    "from src.utils.helper import Config, color_print\n",
    "from src.utils.load import load_model, load_data, save_checkpoint, load_checkpoint\n",
    "from src.models.evaluate import evaluate_model, get_sparsity, get_similarity\n",
    "from src.utils.sampling import SamplingDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"bert-4-128-yahoo\"\n",
    "device = torch.device(\"cuda:0\")\n",
    "checkpoint = None\n",
    "batch_size = 16\n",
    "num_workers = 4\n",
    "num_samples = 128\n",
    "ratio = 0.5\n",
    "seed = 44"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(name, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the model.\n",
      "{'architectures': 'bert',\n",
      " 'dataset_name': 'YahooAnswersTopics',\n",
      " 'model_name': 'models/bert-4-128-yahoo',\n",
      " 'num_labels': 10,\n",
      " 'tokenizer_name': 'fabriceyhc/bert-base-uncased-yahoo_answers_topics'}\n",
      "The model models/bert-4-128-yahoo is loaded.\n"
     ]
    }
   ],
   "source": [
    "model = load_model(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cached dataset YahooAnswersTopics.\n",
      "train.pkl is loaded from cache.\n",
      "valid.pkl is loaded from cache.\n",
      "test.pkl is loaded from cache.\n",
      "The dataset YahooAnswersTopics is loaded\n",
      "{'config_name': 'yahoo_answers_topics',\n",
      " 'features': {'first_column': 'question_title', 'second_column': 'topic'},\n",
      " 'path': 'yahoo_answers_topics'}\n"
     ]
    }
   ],
   "source": [
    "train_dataloader, valid_dataloader, test_dataloader = load_data(\n",
    "    config,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    do_cache=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch\n",
    "import numpy as np\n",
    "from typing import *\n",
    "import torch.nn as nn\n",
    "from functools import partial\n",
    "from transformers.pytorch_utils import (\n",
    "    find_pruneable_heads_and_indices,\n",
    "    prune_linear_layer,\n",
    ")\n",
    "\n",
    "\n",
    "def calculate_head_importance(\n",
    "    model,\n",
    "    config,\n",
    "    data,\n",
    "    normalize_scores_by_layer=True,\n",
    "):\n",
    "    device = config.device\n",
    "    from functools import partial\n",
    "\n",
    "    gradients = {}\n",
    "    context_layers = {}\n",
    "\n",
    "    def save_grad(gradients, layer_idx, grad):\n",
    "        gradients[f\"context_layer_{layer_idx}\"] = grad\n",
    "\n",
    "    def forward_hook(module, input, output, gradients, context_layers, layer_idx):\n",
    "        context_layers[f\"context_layer_{layer_idx}\"] = output[0]\n",
    "        output[0].register_hook(partial(save_grad, gradients, layer_idx))\n",
    "\n",
    "    def reshape(tensors, shape, num_heads):\n",
    "        batch_size = shape[0]\n",
    "        seq_len = shape[1]\n",
    "        head_dim = shape[2] // num_heads\n",
    "        tensors = tensors.reshape(batch_size, seq_len, num_heads, head_dim)\n",
    "        tensors = tensors.permute(0, 2, 1, 3)\n",
    "        return tensors\n",
    "\n",
    "    forward_handles = []\n",
    "\n",
    "    for layer_idx in range(model.bert.config.num_hidden_layers):\n",
    "        self_att = model.bert.encoder.layer[layer_idx].attention.self\n",
    "        handle = self_att.register_forward_hook(\n",
    "            partial(\n",
    "                forward_hook,\n",
    "                gradients=gradients,\n",
    "                context_layers=context_layers,\n",
    "                layer_idx=layer_idx,\n",
    "            )\n",
    "        )\n",
    "        forward_handles.append(handle)\n",
    "\n",
    "    \"\"\"Calculate head importance scores\"\"\"\n",
    "    # Disable dropout\n",
    "    model.eval()\n",
    "    # Device\n",
    "    device = device or next(model.parameters()).device\n",
    "\n",
    "    # Prepare data loader\n",
    "    # Head importance tensor\n",
    "    n_layers = model.bert.config.num_hidden_layers\n",
    "    n_heads = model.bert.config.num_attention_heads\n",
    "    head_importance = torch.zeros(n_layers, n_heads).to(device)\n",
    "    tot_tokens = 0\n",
    "    first_batch = next(iter(data))\n",
    "    is_embeds = \"embeddings\" in first_batch\n",
    "    for step, batch in enumerate(data):\n",
    "        if is_embeds:\n",
    "            embeddings = batch[\"embeddings\"].to(device)\n",
    "        else:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "        input_mask = batch[\"attention_mask\"].to(device)\n",
    "        label_ids = batch[\"labels\"].to(device)\n",
    "        # Compute gradients\n",
    "        if is_embeds:\n",
    "            loss = model(\n",
    "                inputs_embeds=embeddings, attention_mask=input_mask, labels=label_ids\n",
    "            ).loss\n",
    "        else:\n",
    "            loss = model(input_ids, attention_mask=input_mask, labels=label_ids).loss\n",
    "        loss.backward()\n",
    "\n",
    "        for layer_idx in range(model.bert.config.num_hidden_layers):\n",
    "            ctx = context_layers[f\"context_layer_{layer_idx}\"]\n",
    "            grad_ctx = gradients[f\"context_layer_{layer_idx}\"]\n",
    "            shape = ctx.shape\n",
    "            ctx = reshape(ctx, shape, n_heads)\n",
    "            grad_ctx = reshape(grad_ctx, shape, n_heads)\n",
    "\n",
    "            # Take the dot\n",
    "            dot = torch.einsum(\"bhli,bhli->bhl\", [grad_ctx, ctx])\n",
    "            head_importance[layer_idx] += dot.abs().sum(-1).sum(0).detach()\n",
    "            del ctx, grad_ctx, dot\n",
    "\n",
    "        tot_tokens += input_mask.float().detach().sum().data\n",
    "\n",
    "    head_importance[:-1] /= tot_tokens\n",
    "\n",
    "    for handle in forward_handles:\n",
    "        handle.remove()\n",
    "    return head_importance\n",
    "\n",
    "def normalize(tensors):\n",
    "    exponent = 2\n",
    "    norm_by_layer = torch.pow(\n",
    "        torch.pow(tensors, exponent).sum(-1), 1 / exponent\n",
    "    )\n",
    "    tensors /= norm_by_layer.unsqueeze(-1) + 1e-20\n",
    "    return tensors\n",
    "\n",
    "def head_importance_prunning(\n",
    "    model, prune_list\n",
    "):\n",
    "        pruned_heads = set()\n",
    "\n",
    "        for layer_index, head_index in prune_list:\n",
    "            if (layer_index, head_index) not in pruned_heads:\n",
    "                prune_heads(\n",
    "                    model.bert.encoder.layer[layer_index].attention,\n",
    "                    [head_index],\n",
    "                    method=None,\n",
    "                )\n",
    "                pruned_heads.add((layer_index, head_index))\n",
    "        print(sorted(pruned_heads))\n",
    "\n",
    "\n",
    "def prune_heads(layer, heads, method):\n",
    "    if len(heads) == 0:\n",
    "        return\n",
    "    heads, index = find_pruneable_heads_and_indices(\n",
    "        heads,\n",
    "        layer.self.num_attention_heads,\n",
    "        layer.self.attention_head_size,\n",
    "        layer.pruned_heads,\n",
    "    )\n",
    "\n",
    "    # if method == \"unstructed\":\n",
    "    layer.self.query = zero_out_head_weights(\n",
    "        layer.self.query, heads, layer.self.attention_head_size\n",
    "    )\n",
    "    layer.self.key = zero_out_head_weights(\n",
    "        layer.self.key, heads, layer.self.attention_head_size\n",
    "    )\n",
    "    layer.self.value = zero_out_head_weights(\n",
    "        layer.self.value, heads, layer.self.attention_head_size\n",
    "    )\n",
    "    layer.output.dense = zero_out_head_weights(\n",
    "        layer.output.dense, heads, layer.self.attention_head_size, dim=1\n",
    "    )\n",
    "    # elif method == \"structed\":\n",
    "    #     layer.self.query = prune_linear_layer(layer.self.query, index)\n",
    "    #     layer.self.key = prune_linear_layer(layer.self.key, index)\n",
    "    #     layer.self.value = prune_linear_layer(layer.self.value, index)\n",
    "    #     layer.output.dense = prune_linear_layer(layer.output.dense, index)\n",
    "\n",
    "    #     layer.self.num_attention_heads = layer.self.num_attention_heads - len(heads)\n",
    "    #     layer.self.all_head_size = layer.self.attention_head_size *  layer.self.num_attention_heads\n",
    "    #     layer.pruned_heads = layer.pruned_heads.union(heads)\n",
    "\n",
    "\n",
    "def zero_out_head_weights(\n",
    "    layer: nn.Linear, heads: Set[int], head_size: int, dim: int = 0\n",
    ") -> nn.Linear:\n",
    "    \"\"\"\n",
    "    Zero out the weights of the specified heads in the linear layer.\n",
    "\n",
    "    Args:\n",
    "        layer (`torch.nn.Linear`): The layer to modify.\n",
    "        heads (`Set[int]`): The indices of heads to zero out.\n",
    "        head_size (`int`): The size of each head.\n",
    "        dim (`int`, *optional*, defaults to 0): The dimension on which to zero out the weights.\n",
    "\n",
    "    Returns:\n",
    "        `torch.nn.Linear`: The modified layer with weights of specified heads zeroed out.\n",
    "    \"\"\"\n",
    "    for head in heads:\n",
    "        start_index = head * head_size\n",
    "        end_index = (head + 1) * head_size\n",
    "        if dim == 0:\n",
    "            layer.weight.data[start_index:end_index] = 0\n",
    "        elif dim == 1:\n",
    "            layer.weight.data[:, start_index:end_index] = 0\n",
    "\n",
    "    return layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.evaluate import (\n",
    "    evaluate_model,\n",
    "    get_sparsity,\n",
    "    get_similarity,\n",
    "    get_perplexity,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0), (0, 1), (0, 2), (0, 3)]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "251b5f15bbb84c5fa09c1a354c3b4772",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating the model:   0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.3199\n",
      "Precision: 0.6381, Recall: 0.5909, F1-Score: 0.5984\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.4615    0.5508    0.5022      2992\n",
      "           1     0.6804    0.3920    0.4975      2992\n",
      "           2     0.7023    0.5780    0.6341      3012\n",
      "           3     0.3284    0.6464    0.4356      2998\n",
      "           4     0.7947    0.6757    0.7304      2973\n",
      "           5     0.8383    0.7420    0.7872      3054\n",
      "           6     0.6815    0.3876    0.4942      3003\n",
      "           7     0.5336    0.6700    0.5941      3012\n",
      "           8     0.6162    0.6338    0.6249      2982\n",
      "           9     0.7438    0.6328    0.6838      2982\n",
      "\n",
      "    accuracy                         0.5911     30000\n",
      "   macro avg     0.6381    0.5909    0.5984     30000\n",
      "weighted avg     0.6383    0.5911    0.5986     30000\n",
      "\n",
      "adding eps to diagonal and taking inverse\n",
      "taking square root\n",
      "dot products...\n",
      "trying to take final svd\n",
      "computed everything!\n",
      "adding eps to diagonal and taking inverse\n",
      "taking square root\n",
      "dot products...\n",
      "trying to take final svd\n",
      "computed everything!\n",
      "CCA coefficients mean concern: 0.9898660342537046\n",
      "CCA coefficients mean non-concern: 0.9837386100704834\n",
      "Linear CKA concern: 0.986276174489725\n",
      "Linear CKA non-concern: 0.9876894314449227\n",
      "Kernel CKA concern: 0.9614444660538469\n",
      "Kernel CKA non-concern: 0.9568458545335711\n",
      "adding eps to diagonal and taking inverse\n",
      "taking square root\n",
      "dot products...\n",
      "trying to take final svd\n",
      "computed everything!\n",
      "adding eps to diagonal and taking inverse\n",
      "taking square root\n",
      "dot products...\n",
      "trying to take final svd\n",
      "computed everything!\n",
      "CCA coefficients mean concern: 0.9885835285992843\n",
      "CCA coefficients mean non-concern: 0.9837363092405998\n",
      "Linear CKA concern: 0.9736715999577928\n",
      "Linear CKA non-concern: 0.9888269115538362\n",
      "Kernel CKA concern: 0.9309221111404613\n",
      "Kernel CKA non-concern: 0.960527084132962\n",
      "adding eps to diagonal and taking inverse\n",
      "taking square root\n",
      "dot products...\n",
      "trying to take final svd\n",
      "computed everything!\n",
      "adding eps to diagonal and taking inverse\n",
      "taking square root\n",
      "dot products...\n",
      "trying to take final svd\n",
      "computed everything!\n",
      "CCA coefficients mean concern: 0.9884268783650859\n",
      "CCA coefficients mean non-concern: 0.9841275094892032\n",
      "Linear CKA concern: 0.9778943671718997\n",
      "Linear CKA non-concern: 0.9880949820060444\n",
      "Kernel CKA concern: 0.9392917246030018\n",
      "Kernel CKA non-concern: 0.9575958998068025\n",
      "adding eps to diagonal and taking inverse\n",
      "taking square root\n",
      "dot products...\n",
      "trying to take final svd\n",
      "computed everything!\n",
      "adding eps to diagonal and taking inverse\n",
      "taking square root\n",
      "dot products...\n",
      "trying to take final svd\n",
      "computed everything!\n",
      "CCA coefficients mean concern: 0.9895412942576179\n",
      "CCA coefficients mean non-concern: 0.9839499932675828\n",
      "Linear CKA concern: 0.9805303858387322\n",
      "Linear CKA non-concern: 0.9894152675234984\n",
      "Kernel CKA concern: 0.9476124668891329\n",
      "Kernel CKA non-concern: 0.9600457165325306\n",
      "adding eps to diagonal and taking inverse\n",
      "taking square root\n",
      "dot products...\n",
      "trying to take final svd\n",
      "computed everything!\n",
      "adding eps to diagonal and taking inverse\n",
      "taking square root\n",
      "dot products...\n",
      "trying to take final svd\n",
      "computed everything!\n",
      "CCA coefficients mean concern: 0.9817767413629173\n",
      "CCA coefficients mean non-concern: 0.9855752804646125\n",
      "Linear CKA concern: 0.9460872822690838\n",
      "Linear CKA non-concern: 0.9886920264570627\n",
      "Kernel CKA concern: 0.8917833653219043\n",
      "Kernel CKA non-concern: 0.9600858957680439\n",
      "adding eps to diagonal and taking inverse\n",
      "taking square root\n",
      "dot products...\n",
      "trying to take final svd\n",
      "computed everything!\n",
      "adding eps to diagonal and taking inverse\n",
      "taking square root\n",
      "dot products...\n",
      "trying to take final svd\n",
      "computed everything!\n",
      "CCA coefficients mean concern: 0.9824251415587967\n",
      "CCA coefficients mean non-concern: 0.9855174363143506\n",
      "Linear CKA concern: 0.9605741187479694\n",
      "Linear CKA non-concern: 0.9891795182854183\n",
      "Kernel CKA concern: 0.9131822884155621\n",
      "Kernel CKA non-concern: 0.9613263557108201\n",
      "adding eps to diagonal and taking inverse\n",
      "taking square root\n",
      "dot products...\n",
      "trying to take final svd\n",
      "computed everything!\n",
      "adding eps to diagonal and taking inverse\n",
      "taking square root\n",
      "dot products...\n",
      "trying to take final svd\n",
      "computed everything!\n",
      "CCA coefficients mean concern: 0.9875923507645153\n",
      "CCA coefficients mean non-concern: 0.9837615190640894\n",
      "Linear CKA concern: 0.9832405634315693\n",
      "Linear CKA non-concern: 0.9881819792079423\n",
      "Kernel CKA concern: 0.9527488632395358\n",
      "Kernel CKA non-concern: 0.9576252175499673\n",
      "adding eps to diagonal and taking inverse\n",
      "taking square root\n",
      "dot products...\n",
      "trying to take final svd\n",
      "computed everything!\n",
      "adding eps to diagonal and taking inverse\n",
      "taking square root\n",
      "dot products...\n",
      "trying to take final svd\n",
      "computed everything!\n",
      "CCA coefficients mean concern: 0.9856417548190847\n",
      "CCA coefficients mean non-concern: 0.9842902048717237\n",
      "Linear CKA concern: 0.983277358530145\n",
      "Linear CKA non-concern: 0.9877203276580877\n",
      "Kernel CKA concern: 0.9486507973223653\n",
      "Kernel CKA non-concern: 0.9575316321465511\n",
      "adding eps to diagonal and taking inverse\n",
      "taking square root\n",
      "dot products...\n",
      "trying to take final svd\n",
      "computed everything!\n",
      "adding eps to diagonal and taking inverse\n",
      "taking square root\n",
      "dot products...\n",
      "trying to take final svd\n",
      "computed everything!\n",
      "CCA coefficients mean concern: 0.9862862774608623\n",
      "CCA coefficients mean non-concern: 0.9845971432008377\n",
      "Linear CKA concern: 0.9773411298708896\n",
      "Linear CKA non-concern: 0.9872178490133626\n",
      "Kernel CKA concern: 0.9351994711994769\n",
      "Kernel CKA non-concern: 0.9563574736740895\n",
      "adding eps to diagonal and taking inverse\n",
      "taking square root\n",
      "dot products...\n",
      "trying to take final svd\n",
      "computed everything!\n",
      "adding eps to diagonal and taking inverse\n",
      "taking square root\n",
      "dot products...\n",
      "trying to take final svd\n",
      "computed everything!\n",
      "CCA coefficients mean concern: 0.9886704419050105\n",
      "CCA coefficients mean non-concern: 0.9837721349692508\n",
      "Linear CKA concern: 0.980066346106735\n",
      "Linear CKA non-concern: 0.9879778822290495\n",
      "Kernel CKA concern: 0.9491083313866788\n",
      "Kernel CKA non-concern: 0.9569677473442919\n",
      "original model's perplexity\n",
      "3.2110652923583984\n",
      "pruned model's perplexity\n",
      "3.567145586013794\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.567145586013794"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prune_list = [(0, 0), (0, 1), (0,2), (0,3)]\n",
    "\n",
    "module = copy.deepcopy(model)\n",
    "\n",
    "head_importance_prunning(module, prune_list)\n",
    "\n",
    "result = evaluate_model(module, config, test_dataloader)\n",
    "for concern in range(config.num_labels):\n",
    "    get_similarity(model, module, valid_dataloader, concern, num_samples, config)\n",
    "print(\"original model's perplexity\")\n",
    "get_perplexity(model, valid_dataloader, config)\n",
    "print(\"pruned model's perplexity\")\n",
    "get_perplexity(module, valid_dataloader, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 0), (1, 1), (1, 2), (1, 3)]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec1924a1612a4dccb22dafef4dc664d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating the model:   0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.2621\n",
      "Precision: 0.6428, Recall: 0.6038, F1-Score: 0.6115\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.4305    0.5943    0.4993      2992\n",
      "           1     0.6753    0.4783    0.5600      2992\n",
      "           2     0.6894    0.5916    0.6368      3012\n",
      "           3     0.3475    0.6181    0.4448      2998\n",
      "           4     0.7432    0.7592    0.7511      2973\n",
      "           5     0.8539    0.7403    0.7931      3054\n",
      "           6     0.6627    0.4063    0.5037      3003\n",
      "           7     0.6209    0.6301    0.6255      3012\n",
      "           8     0.6287    0.6251    0.6269      2982\n",
      "           9     0.7764    0.5949    0.6736      2982\n",
      "\n",
      "    accuracy                         0.6039     30000\n",
      "   macro avg     0.6428    0.6038    0.6115     30000\n",
      "weighted avg     0.6431    0.6039    0.6117     30000\n",
      "\n",
      "adding eps to diagonal and taking inverse\n",
      "taking square root\n",
      "dot products...\n",
      "trying to take final svd\n",
      "computed everything!\n",
      "adding eps to diagonal and taking inverse\n",
      "taking square root\n",
      "dot products...\n",
      "trying to take final svd\n",
      "computed everything!\n",
      "CCA coefficients mean concern: 0.9927118769459594\n",
      "CCA coefficients mean non-concern: 0.9913338846440458\n",
      "Linear CKA concern: 0.9793825623771117\n",
      "Linear CKA non-concern: 0.9847936005959168\n",
      "Kernel CKA concern: 0.9528143909170907\n",
      "Kernel CKA non-concern: 0.9668995424025586\n",
      "adding eps to diagonal and taking inverse\n",
      "taking square root\n",
      "dot products...\n",
      "trying to take final svd\n",
      "computed everything!\n",
      "adding eps to diagonal and taking inverse\n",
      "taking square root\n",
      "dot products...\n",
      "trying to take final svd\n",
      "computed everything!\n",
      "CCA coefficients mean concern: 0.99336399586348\n",
      "CCA coefficients mean non-concern: 0.9911900044404758\n",
      "Linear CKA concern: 0.9768860161414665\n",
      "Linear CKA non-concern: 0.9853891474137728\n",
      "Kernel CKA concern: 0.9495218695408179\n",
      "Kernel CKA non-concern: 0.9673961267214672\n",
      "adding eps to diagonal and taking inverse\n",
      "taking square root\n",
      "dot products...\n",
      "trying to take final svd\n",
      "computed everything!\n",
      "adding eps to diagonal and taking inverse\n",
      "taking square root\n",
      "dot products...\n",
      "trying to take final svd\n",
      "computed everything!\n",
      "CCA coefficients mean concern: 0.9925227900710877\n",
      "CCA coefficients mean non-concern: 0.9913659158276394\n",
      "Linear CKA concern: 0.9750337706236076\n",
      "Linear CKA non-concern: 0.9849827620885888\n",
      "Kernel CKA concern: 0.9432802962813841\n",
      "Kernel CKA non-concern: 0.9664112190238698\n",
      "adding eps to diagonal and taking inverse\n",
      "taking square root\n",
      "dot products...\n",
      "trying to take final svd\n",
      "computed everything!\n",
      "adding eps to diagonal and taking inverse\n",
      "taking square root\n",
      "dot products...\n",
      "trying to take final svd\n",
      "computed everything!\n",
      "CCA coefficients mean concern: 0.9934953098550596\n",
      "CCA coefficients mean non-concern: 0.9913918510624777\n",
      "Linear CKA concern: 0.9809786791185963\n",
      "Linear CKA non-concern: 0.9851838290736183\n",
      "Kernel CKA concern: 0.9604599292942402\n",
      "Kernel CKA non-concern: 0.9656948851196627\n",
      "adding eps to diagonal and taking inverse\n",
      "taking square root\n",
      "dot products...\n",
      "trying to take final svd\n",
      "computed everything!\n",
      "adding eps to diagonal and taking inverse\n",
      "taking square root\n",
      "dot products...\n",
      "trying to take final svd\n",
      "computed everything!\n",
      "CCA coefficients mean concern: 0.9916815875773175\n",
      "CCA coefficients mean non-concern: 0.9916938134280985\n",
      "Linear CKA concern: 0.9770383863057466\n",
      "Linear CKA non-concern: 0.9848355099336968\n",
      "Kernel CKA concern: 0.9569717189490259\n",
      "Kernel CKA non-concern: 0.9648434446689937\n",
      "adding eps to diagonal and taking inverse\n",
      "taking square root\n",
      "dot products...\n",
      "trying to take final svd\n",
      "computed everything!\n",
      "adding eps to diagonal and taking inverse\n",
      "taking square root\n",
      "dot products...\n",
      "trying to take final svd\n",
      "computed everything!\n",
      "CCA coefficients mean concern: 0.9906829934531124\n",
      "CCA coefficients mean non-concern: 0.9917558322558403\n",
      "Linear CKA concern: 0.9793967000607161\n",
      "Linear CKA non-concern: 0.9849404229644195\n",
      "Kernel CKA concern: 0.9664183953139229\n",
      "Kernel CKA non-concern: 0.9646406403994957\n",
      "adding eps to diagonal and taking inverse\n",
      "taking square root\n",
      "dot products...\n",
      "trying to take final svd\n",
      "computed everything!\n",
      "adding eps to diagonal and taking inverse\n",
      "taking square root\n",
      "dot products...\n",
      "trying to take final svd\n",
      "computed everything!\n",
      "CCA coefficients mean concern: 0.9916746620330714\n",
      "CCA coefficients mean non-concern: 0.9910999948448225\n",
      "Linear CKA concern: 0.9838409858418516\n",
      "Linear CKA non-concern: 0.9845652598402428\n",
      "Kernel CKA concern: 0.9596405960565416\n",
      "Kernel CKA non-concern: 0.9660439605054818\n",
      "adding eps to diagonal and taking inverse\n",
      "taking square root\n",
      "dot products...\n",
      "trying to take final svd\n",
      "computed everything!\n",
      "adding eps to diagonal and taking inverse\n",
      "taking square root\n",
      "dot products...\n",
      "trying to take final svd\n",
      "computed everything!\n",
      "CCA coefficients mean concern: 0.9920509942655\n",
      "CCA coefficients mean non-concern: 0.9913350525969364\n",
      "Linear CKA concern: 0.986995914572017\n",
      "Linear CKA non-concern: 0.9844965194641383\n",
      "Kernel CKA concern: 0.9684964661185809\n",
      "Kernel CKA non-concern: 0.9654686760975746\n",
      "adding eps to diagonal and taking inverse\n",
      "taking square root\n",
      "dot products...\n",
      "trying to take final svd\n",
      "computed everything!\n",
      "adding eps to diagonal and taking inverse\n",
      "taking square root\n",
      "dot products...\n",
      "trying to take final svd\n",
      "computed everything!\n",
      "CCA coefficients mean concern: 0.991005221903442\n",
      "CCA coefficients mean non-concern: 0.9916062984974939\n",
      "Linear CKA concern: 0.9820465282992582\n",
      "Linear CKA non-concern: 0.9846758746632178\n",
      "Kernel CKA concern: 0.9537274795995746\n",
      "Kernel CKA non-concern: 0.9658185797016464\n",
      "adding eps to diagonal and taking inverse\n",
      "taking square root\n",
      "dot products...\n",
      "trying to take final svd\n",
      "computed everything!\n",
      "adding eps to diagonal and taking inverse\n",
      "taking square root\n",
      "dot products...\n",
      "trying to take final svd\n",
      "computed everything!\n",
      "CCA coefficients mean concern: 0.9920478486147942\n",
      "CCA coefficients mean non-concern: 0.9910519607332932\n",
      "Linear CKA concern: 0.9746276919019098\n",
      "Linear CKA non-concern: 0.9847974865536588\n",
      "Kernel CKA concern: 0.935061947914132\n",
      "Kernel CKA non-concern: 0.9664029430282817\n",
      "original model's perplexity\n",
      "3.2110652923583984\n",
      "pruned model's perplexity\n",
      "3.337691307067871\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.337691307067871"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prune_list = [(1, 0), (1, 1), (1,2), (1,3)]\n",
    "\n",
    "module = copy.deepcopy(model)\n",
    "\n",
    "head_importance_prunning(module, prune_list)\n",
    "\n",
    "result = evaluate_model(module, config, test_dataloader)\n",
    "for concern in range(config.num_labels):\n",
    "    get_similarity(model, module, valid_dataloader, concern, num_samples, config)\n",
    "print(\"original model's perplexity\")\n",
    "get_perplexity(model, valid_dataloader, config)\n",
    "print(\"pruned model's perplexity\")\n",
    "get_perplexity(module, valid_dataloader, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2, 0), (2, 1), (2, 2), (2, 3)]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acacd0cf01644dc184ce7f605d36584d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating the model:   0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.2475\n",
      "Precision: 0.6431, Recall: 0.6069, F1-Score: 0.6149\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5066    0.5157    0.5111      2992\n",
      "           1     0.6570    0.5000    0.5678      2992\n",
      "           2     0.6923    0.6125    0.6500      3012\n",
      "           3     0.3238    0.6448    0.4311      2998\n",
      "           4     0.7521    0.7346    0.7432      2973\n",
      "           5     0.8246    0.7590    0.7905      3054\n",
      "           6     0.6528    0.4126    0.5056      3003\n",
      "           7     0.6578    0.5744    0.6133      3012\n",
      "           8     0.6226    0.6616    0.6415      2982\n",
      "           9     0.7415    0.6543    0.6952      2982\n",
      "\n",
      "    accuracy                         0.6071     30000\n",
      "   macro avg     0.6431    0.6069    0.6149     30000\n",
      "weighted avg     0.6434    0.6071    0.6151     30000\n",
      "\n",
      "adding eps to diagonal and taking inverse\n",
      "taking square root\n",
      "dot products...\n",
      "trying to take final svd\n",
      "computed everything!\n",
      "adding eps to diagonal and taking inverse\n",
      "taking square root\n",
      "dot products...\n",
      "trying to take final svd\n",
      "computed everything!\n",
      "CCA coefficients mean concern: 0.9945637046233845\n",
      "CCA coefficients mean non-concern: 0.9927001821477937\n",
      "Linear CKA concern: 0.97091682483898\n",
      "Linear CKA non-concern: 0.979359355257016\n",
      "Kernel CKA concern: 0.9449534626016973\n",
      "Kernel CKA non-concern: 0.956769651807513\n",
      "adding eps to diagonal and taking inverse\n",
      "taking square root\n",
      "dot products...\n",
      "trying to take final svd\n",
      "computed everything!\n",
      "adding eps to diagonal and taking inverse\n",
      "taking square root\n",
      "dot products...\n",
      "trying to take final svd\n",
      "computed everything!\n",
      "CCA coefficients mean concern: 0.9950844367812794\n",
      "CCA coefficients mean non-concern: 0.992609532800892\n",
      "Linear CKA concern: 0.9723676525237467\n",
      "Linear CKA non-concern: 0.9798235268253355\n",
      "Kernel CKA concern: 0.9555790473543059\n",
      "Kernel CKA non-concern: 0.9560839794981245\n",
      "adding eps to diagonal and taking inverse\n",
      "taking square root\n",
      "dot products...\n",
      "trying to take final svd\n",
      "computed everything!\n",
      "adding eps to diagonal and taking inverse\n",
      "taking square root\n",
      "dot products...\n",
      "trying to take final svd\n",
      "computed everything!\n",
      "CCA coefficients mean concern: 0.995127775129187\n",
      "CCA coefficients mean non-concern: 0.9927083902230999\n",
      "Linear CKA concern: 0.9755903913472223\n",
      "Linear CKA non-concern: 0.9792234417974205\n",
      "Kernel CKA concern: 0.9506177600051148\n",
      "Kernel CKA non-concern: 0.9567373683280033\n",
      "adding eps to diagonal and taking inverse\n",
      "taking square root\n",
      "dot products...\n",
      "trying to take final svd\n",
      "computed everything!\n",
      "adding eps to diagonal and taking inverse\n",
      "taking square root\n",
      "dot products...\n",
      "trying to take final svd\n",
      "computed everything!\n",
      "CCA coefficients mean concern: 0.994841952709571\n",
      "CCA coefficients mean non-concern: 0.9929742763336842\n",
      "Linear CKA concern: 0.9722470642632911\n",
      "Linear CKA non-concern: 0.9802709910598159\n",
      "Kernel CKA concern: 0.9471412729666883\n",
      "Kernel CKA non-concern: 0.9563269394463483\n",
      "adding eps to diagonal and taking inverse\n",
      "taking square root\n",
      "dot products...\n",
      "trying to take final svd\n",
      "computed everything!\n",
      "adding eps to diagonal and taking inverse\n",
      "taking square root\n",
      "dot products...\n",
      "trying to take final svd\n",
      "computed everything!\n",
      "CCA coefficients mean concern: 0.9936653456335047\n",
      "CCA coefficients mean non-concern: 0.9929911824098107\n",
      "Linear CKA concern: 0.9806295296904977\n",
      "Linear CKA non-concern: 0.9787624139192829\n",
      "Kernel CKA concern: 0.9615144206468852\n",
      "Kernel CKA non-concern: 0.9552720778632052\n",
      "adding eps to diagonal and taking inverse\n",
      "taking square root\n",
      "dot products...\n",
      "trying to take final svd\n",
      "computed everything!\n",
      "adding eps to diagonal and taking inverse\n",
      "taking square root\n",
      "dot products...\n",
      "trying to take final svd\n",
      "computed everything!\n",
      "CCA coefficients mean concern: 0.9909318041764704\n",
      "CCA coefficients mean non-concern: 0.9938049731839668\n",
      "Linear CKA concern: 0.965062154984126\n",
      "Linear CKA non-concern: 0.9793377679948556\n",
      "Kernel CKA concern: 0.924292373732533\n",
      "Kernel CKA non-concern: 0.9569804343694246\n",
      "adding eps to diagonal and taking inverse\n",
      "taking square root\n",
      "dot products...\n",
      "trying to take final svd\n",
      "computed everything!\n",
      "adding eps to diagonal and taking inverse\n",
      "taking square root\n",
      "dot products...\n",
      "trying to take final svd\n",
      "computed everything!\n",
      "CCA coefficients mean concern: 0.9941679854076713\n",
      "CCA coefficients mean non-concern: 0.9925839381983483\n",
      "Linear CKA concern: 0.9782066178028089\n",
      "Linear CKA non-concern: 0.9791602945867276\n",
      "Kernel CKA concern: 0.9509974010231843\n",
      "Kernel CKA non-concern: 0.9567539913333567\n",
      "adding eps to diagonal and taking inverse\n",
      "taking square root\n",
      "dot products...\n",
      "trying to take final svd\n",
      "computed everything!\n",
      "adding eps to diagonal and taking inverse\n",
      "taking square root\n",
      "dot products...\n",
      "trying to take final svd\n",
      "computed everything!\n",
      "CCA coefficients mean concern: 0.9929828253251928\n",
      "CCA coefficients mean non-concern: 0.992989383115364\n",
      "Linear CKA concern: 0.9741230984535407\n",
      "Linear CKA non-concern: 0.9793651519492642\n",
      "Kernel CKA concern: 0.95000222211782\n",
      "Kernel CKA non-concern: 0.956096381380103\n",
      "adding eps to diagonal and taking inverse\n",
      "taking square root\n",
      "dot products...\n",
      "trying to take final svd\n",
      "computed everything!\n",
      "adding eps to diagonal and taking inverse\n",
      "taking square root\n",
      "dot products...\n",
      "trying to take final svd\n",
      "computed everything!\n",
      "CCA coefficients mean concern: 0.9947959446375504\n",
      "CCA coefficients mean non-concern: 0.9928969877622471\n",
      "Linear CKA concern: 0.9842306172013182\n",
      "Linear CKA non-concern: 0.9780911546253297\n",
      "Kernel CKA concern: 0.9620212751853415\n",
      "Kernel CKA non-concern: 0.9548656071608429\n",
      "adding eps to diagonal and taking inverse\n",
      "taking square root\n",
      "dot products...\n",
      "trying to take final svd\n",
      "computed everything!\n",
      "adding eps to diagonal and taking inverse\n",
      "taking square root\n",
      "dot products...\n",
      "trying to take final svd\n",
      "computed everything!\n",
      "CCA coefficients mean concern: 0.9947275713153667\n",
      "CCA coefficients mean non-concern: 0.9927349565956582\n",
      "Linear CKA concern: 0.9780855415643878\n",
      "Linear CKA non-concern: 0.979262102320512\n",
      "Kernel CKA concern: 0.963198002017525\n",
      "Kernel CKA non-concern: 0.9555369986183939\n",
      "original model's perplexity\n",
      "3.2110652923583984\n",
      "pruned model's perplexity\n",
      "3.3074309825897217\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.3074309825897217"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prune_list = [(2, 0), (2, 1), (2,2), (2,3)]\n",
    "\n",
    "module = copy.deepcopy(model)\n",
    "\n",
    "head_importance_prunning(module, prune_list)\n",
    "\n",
    "result = evaluate_model(module, config, test_dataloader)\n",
    "for concern in range(config.num_labels):\n",
    "    get_similarity(model, module, valid_dataloader, concern, num_samples, config)\n",
    "print(\"original model's perplexity\")\n",
    "get_perplexity(model, valid_dataloader, config)\n",
    "print(\"pruned model's perplexity\")\n",
    "get_perplexity(module, valid_dataloader, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3, 0), (3, 1), (3, 2), (3, 3)]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a40874204d9c4885a1d6e442e65bbd32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating the model:   0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.2442\n",
      "Precision: 0.6263, Recall: 0.6145, F1-Score: 0.6145\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.4883    0.5150    0.5013      2992\n",
      "           1     0.6200    0.5709    0.5944      2992\n",
      "           2     0.6390    0.6335    0.6362      3012\n",
      "           3     0.3763    0.5143    0.4346      2998\n",
      "           4     0.7014    0.7656    0.7321      2973\n",
      "           5     0.7875    0.7839    0.7857      3054\n",
      "           6     0.6865    0.3813    0.4903      3003\n",
      "           7     0.6610    0.6142    0.6367      3012\n",
      "           8     0.6293    0.6536    0.6412      2982\n",
      "           9     0.6736    0.7129    0.6927      2982\n",
      "\n",
      "    accuracy                         0.6146     30000\n",
      "   macro avg     0.6263    0.6145    0.6145     30000\n",
      "weighted avg     0.6265    0.6146    0.6147     30000\n",
      "\n",
      "adding eps to diagonal and taking inverse\n",
      "taking square root\n",
      "dot products...\n",
      "trying to take final svd\n",
      "computed everything!\n",
      "adding eps to diagonal and taking inverse\n",
      "taking square root\n",
      "dot products...\n",
      "trying to take final svd\n",
      "computed everything!\n",
      "CCA coefficients mean concern: 0.9899924175113647\n",
      "CCA coefficients mean non-concern: 0.9888834651486557\n",
      "Linear CKA concern: 0.9057751421405394\n",
      "Linear CKA non-concern: 0.883734932021556\n",
      "Kernel CKA concern: 0.8721449602189334\n",
      "Kernel CKA non-concern: 0.8701141194021889\n",
      "adding eps to diagonal and taking inverse\n",
      "taking square root\n",
      "dot products...\n",
      "trying to take final svd\n",
      "computed everything!\n",
      "adding eps to diagonal and taking inverse\n",
      "taking square root\n",
      "dot products...\n",
      "trying to take final svd\n",
      "computed everything!\n",
      "CCA coefficients mean concern: 0.9909711344499811\n",
      "CCA coefficients mean non-concern: 0.988593266228624\n",
      "Linear CKA concern: 0.8653219073990998\n",
      "Linear CKA non-concern: 0.8900452560668085\n",
      "Kernel CKA concern: 0.8583000752422576\n",
      "Kernel CKA non-concern: 0.873798041451645\n",
      "adding eps to diagonal and taking inverse\n",
      "taking square root\n",
      "dot products...\n",
      "trying to take final svd\n",
      "computed everything!\n",
      "adding eps to diagonal and taking inverse\n",
      "taking square root\n",
      "dot products...\n",
      "trying to take final svd\n",
      "computed everything!\n",
      "CCA coefficients mean concern: 0.9905262617491909\n",
      "CCA coefficients mean non-concern: 0.9889209288031041\n",
      "Linear CKA concern: 0.8862620687408457\n",
      "Linear CKA non-concern: 0.8874853105970901\n",
      "Kernel CKA concern: 0.8680672943241705\n",
      "Kernel CKA non-concern: 0.8732022747908464\n",
      "adding eps to diagonal and taking inverse\n",
      "taking square root\n",
      "dot products...\n",
      "trying to take final svd\n",
      "computed everything!\n",
      "adding eps to diagonal and taking inverse\n",
      "taking square root\n",
      "dot products...\n",
      "trying to take final svd\n",
      "computed everything!\n",
      "CCA coefficients mean concern: 0.9909257272615868\n",
      "CCA coefficients mean non-concern: 0.9890834060626578\n",
      "Linear CKA concern: 0.8774298476529973\n",
      "Linear CKA non-concern: 0.8896622146280663\n",
      "Kernel CKA concern: 0.8679247066604043\n",
      "Kernel CKA non-concern: 0.8692252987611214\n",
      "adding eps to diagonal and taking inverse\n",
      "taking square root\n",
      "dot products...\n",
      "trying to take final svd\n",
      "computed everything!\n",
      "adding eps to diagonal and taking inverse\n",
      "taking square root\n",
      "dot products...\n",
      "trying to take final svd\n",
      "computed everything!\n",
      "CCA coefficients mean concern: 0.9871572697786873\n",
      "CCA coefficients mean non-concern: 0.9890910324536841\n",
      "Linear CKA concern: 0.8733570734022749\n",
      "Linear CKA non-concern: 0.8921656025344898\n",
      "Kernel CKA concern: 0.8953728054260223\n",
      "Kernel CKA non-concern: 0.870240011408906\n",
      "adding eps to diagonal and taking inverse\n",
      "taking square root\n",
      "dot products...\n",
      "trying to take final svd\n",
      "computed everything!\n",
      "adding eps to diagonal and taking inverse\n",
      "taking square root\n",
      "dot products...\n",
      "trying to take final svd\n",
      "computed everything!\n",
      "CCA coefficients mean concern: 0.985881958511744\n",
      "CCA coefficients mean non-concern: 0.9897769710009802\n",
      "Linear CKA concern: 0.8633363965549703\n",
      "Linear CKA non-concern: 0.889539508387314\n",
      "Kernel CKA concern: 0.8883241915883986\n",
      "Kernel CKA non-concern: 0.8673599901867949\n",
      "adding eps to diagonal and taking inverse\n",
      "taking square root\n",
      "dot products...\n",
      "trying to take final svd\n",
      "computed everything!\n",
      "adding eps to diagonal and taking inverse\n",
      "taking square root\n",
      "dot products...\n",
      "trying to take final svd\n",
      "computed everything!\n",
      "CCA coefficients mean concern: 0.9901843071046116\n",
      "CCA coefficients mean non-concern: 0.9886588243809716\n",
      "Linear CKA concern: 0.8719019177240918\n",
      "Linear CKA non-concern: 0.8868339897343942\n",
      "Kernel CKA concern: 0.8648563534192346\n",
      "Kernel CKA non-concern: 0.872537544793581\n",
      "adding eps to diagonal and taking inverse\n",
      "taking square root\n",
      "dot products...\n",
      "trying to take final svd\n",
      "computed everything!\n",
      "adding eps to diagonal and taking inverse\n",
      "taking square root\n",
      "dot products...\n",
      "trying to take final svd\n",
      "computed everything!\n",
      "CCA coefficients mean concern: 0.9891018894036853\n",
      "CCA coefficients mean non-concern: 0.9892670599069665\n",
      "Linear CKA concern: 0.8820912212420201\n",
      "Linear CKA non-concern: 0.8875709547984265\n",
      "Kernel CKA concern: 0.875271253536981\n",
      "Kernel CKA non-concern: 0.872319439193542\n",
      "adding eps to diagonal and taking inverse\n",
      "taking square root\n",
      "dot products...\n",
      "trying to take final svd\n",
      "computed everything!\n",
      "adding eps to diagonal and taking inverse\n",
      "taking square root\n",
      "dot products...\n",
      "trying to take final svd\n",
      "computed everything!\n",
      "CCA coefficients mean concern: 0.9921876418400329\n",
      "CCA coefficients mean non-concern: 0.9888089213816649\n",
      "Linear CKA concern: 0.9260635028653189\n",
      "Linear CKA non-concern: 0.8808463544120684\n",
      "Kernel CKA concern: 0.907114124975241\n",
      "Kernel CKA non-concern: 0.8667949108136984\n",
      "adding eps to diagonal and taking inverse\n",
      "taking square root\n",
      "dot products...\n",
      "trying to take final svd\n",
      "computed everything!\n",
      "adding eps to diagonal and taking inverse\n",
      "taking square root\n",
      "dot products...\n",
      "trying to take final svd\n",
      "computed everything!\n",
      "CCA coefficients mean concern: 0.9899302413588108\n",
      "CCA coefficients mean non-concern: 0.9888493598848573\n",
      "Linear CKA concern: 0.8731313931340297\n",
      "Linear CKA non-concern: 0.8878561567601451\n",
      "Kernel CKA concern: 0.8684515532552324\n",
      "Kernel CKA non-concern: 0.8722459717780969\n",
      "original model's perplexity\n",
      "3.2110652923583984\n",
      "pruned model's perplexity\n",
      "3.2736523151397705\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.2736523151397705"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prune_list = [(3, 0), (3, 1), (3,2), (3,3)]\n",
    "\n",
    "module = copy.deepcopy(model)\n",
    "\n",
    "head_importance_prunning(module, prune_list)\n",
    "\n",
    "result = evaluate_model(module, config, test_dataloader)\n",
    "for concern in range(config.num_labels):\n",
    "    get_similarity(model, module, valid_dataloader, concern, num_samples, config)\n",
    "print(\"original model's perplexity\")\n",
    "get_perplexity(model, valid_dataloader, config)\n",
    "print(\"pruned model's perplexity\")\n",
    "get_perplexity(module, valid_dataloader, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "decomposetransformer-UESb9BbT-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
