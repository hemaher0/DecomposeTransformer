{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "sys.path.append(\"../../../\")\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import copy\n",
        "import torch\n",
        "from datetime import datetime\n",
        "from src.utils.helper import Config, color_print\n",
        "from src.utils.load import save_checkpoint\n",
        "from src.utils.load import load_model, load_data, save_checkpoint\n",
        "from src.models.evaluate import evaluate_model, get_sparsity, get_similarity\n",
        "from src.utils.sampling import SamplingDataset\n",
        "from src.pruning.prune_head import head_importance_prunning\n",
        "from src.pruning.prune import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "input_size = 28 * 28\n",
        "num_classes = 10\n",
        "num_epochs = 5\n",
        "batch_size = 100\n",
        "learning_rate = 0.001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "name = \"MNIST\"\n",
        "device = torch.device(\"cuda:0\")\n",
        "checkpoint = None\n",
        "batch_size = 16\n",
        "num_workers = 4\n",
        "num_samples = 128\n",
        "ci_ratio = 0.3\n",
        "seed = 44"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SimpleDNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleDNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(784, 512)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256, 128)\n",
        "        self.fc4 = nn.Linear(128, 64)\n",
        "        self.fc5 = nn.Linear(64, 32)\n",
        "        self.fc6 = nn.Linear(32, 10)\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "        self.bn1 = nn.BatchNorm1d(512)\n",
        "        self.bn2 = nn.BatchNorm1d(256)\n",
        "        self.bn3 = nn.BatchNorm1d(128)\n",
        "        self.bn4 = nn.BatchNorm1d(64)\n",
        "        self.bn5 = nn.BatchNorm1d(32)\n",
        "\n",
        "    def forward(self, x, output_hidden_states=False):\n",
        "        hidden_states = []\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        x = self.bn1(self.fc1(x))\n",
        "        if output_hidden_states:\n",
        "            hidden_states.append(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.bn2(self.fc2(x))\n",
        "        if output_hidden_states:\n",
        "            hidden_states.append(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.bn3(self.fc3(x))\n",
        "        if output_hidden_states:\n",
        "            hidden_states.append(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.bn4(self.fc4(x))\n",
        "        if output_hidden_states:\n",
        "            hidden_states.append(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.bn5(self.fc5(x))\n",
        "        if output_hidden_states:\n",
        "            hidden_states.append(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.fc6(x)\n",
        "        if output_hidden_states:\n",
        "            hidden_states.append(x)\n",
        "\n",
        "        if output_hidden_states:\n",
        "            return {\"logits\": x, \"hidden_states\": hidden_states}\n",
        "        else:\n",
        "            return {\"logits\": x}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = SimpleDNN()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SimpleDNN(\n",
              "  (fc1): Linear(in_features=784, out_features=512, bias=True)\n",
              "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
              "  (fc3): Linear(in_features=256, out_features=128, bias=True)\n",
              "  (fc4): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (fc5): Linear(in_features=64, out_features=32, bias=True)\n",
              "  (fc6): Linear(in_features=32, out_features=10, bias=True)\n",
              "  (relu): ReLU()\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              "  (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (bn3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (bn4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (bn5): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              ")"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "config = Config(name, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading cached dataset MNIST.\n",
            "train.pkl is loaded from cache.\n",
            "valid.pkl is loaded from cache.\n",
            "test.pkl is loaded from cache.\n",
            "The dataset MNIST is loaded\n",
            "{'dataset_name': 'MNIST', 'path': 'ylecun/mnist', 'config_name': 'mnist', 'features': {'first_column': 'image', 'second_column': 'label'}, 'cache_dir': 'Datasets/MNIST', 'task_type': 'image_classification'}\n"
          ]
        }
      ],
      "source": [
        "train_dataloader, valid_dataloader, test_dataloader = load_data(\n",
        "    config,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=num_workers,\n",
        "    do_cache=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# for epoch in range(num_epochs):\n",
        "#     for i, batch in enumerate(train_dataloader):\n",
        "#         images = batch[\"image\"].float()\n",
        "#         labels = batch[\"labels\"]\n",
        "#         # Forward pass\n",
        "#         outputs = model(images)\n",
        "#         logits = outputs[\"logits\"]\n",
        "#         loss = criterion(logits, labels)\n",
        "\n",
        "#         # Backward and optimize\n",
        "#         optimizer.zero_grad()\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "\n",
        "#         if (i + 1) % 100 == 0:\n",
        "#             print(\n",
        "#                 f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_dataloader)}], Loss: {loss.item():.4f}\"\n",
        "#             )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# torch.save(model.state_dict(), \"Models/MNIST/model.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = SimpleDNN()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.load_state_dict(torch.load(\"Models/MNIST/model.pt\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "144cabc72f0748c8932a7267704fa59f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.1288\n",
            "Precision: 0.9671, Recall: 0.9669, F1-Score: 0.9669\n",
            "              precision    recall  f1-score   support\n",
            "           0       0.98      0.99      0.98       980\n",
            "           1       0.98      0.99      0.98      1135\n",
            "           2       0.97      0.97      0.97      1032\n",
            "           3       0.95      0.98      0.96      1010\n",
            "           4       0.97      0.96      0.96       982\n",
            "           5       0.96      0.96      0.96       892\n",
            "           6       0.97      0.97      0.97       958\n",
            "           7       0.97      0.96      0.96      1028\n",
            "           8       0.97      0.96      0.96       974\n",
            "           9       0.95      0.94      0.95      1009\n",
            "    accuracy                           0.97     10000\n",
            "   macro avg       0.97      0.97      0.97     10000\n",
            "weighted avg       0.97      0.97      0.97     10000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "result = evaluate_model(model, config, test_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluate the pruned model 0\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1e2e74998a23409dba0fae44b7d34d91",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 1.9286\n",
            "Precision: 0.3174, Recall: 0.2617, F1-Score: 0.2069\n",
            "              precision    recall  f1-score   support\n",
            "           0       0.13      1.00      0.23       980\n",
            "           1       0.00      0.00      0.00      1135\n",
            "           2       1.00      0.10      0.18      1032\n",
            "           3       0.98      0.41      0.58      1010\n",
            "           4       0.00      0.00      0.00       982\n",
            "           5       0.51      0.46      0.49       892\n",
            "           6       0.00      0.00      0.00       958\n",
            "           7       0.00      0.00      0.00      1028\n",
            "           8       0.55      0.65      0.59       974\n",
            "           9       0.00      0.00      0.00      1009\n",
            "    accuracy                           0.25     10000\n",
            "   macro avg       0.32      0.26      0.21     10000\n",
            "weighted avg       0.31      0.25      0.20     10000\n",
            "adding eps to diagonal and taking inverse\n",
            "taking square root\n",
            "dot products...\n",
            "trying to take final svd\n",
            "computed everything!\n",
            "adding eps to diagonal and taking inverse\n",
            "taking square root\n",
            "dot products...\n",
            "trying to take final svd\n",
            "computed everything!\n",
            "CCA coefficients mean concern: (np.float64(0.6988306795909656), np.float64(0.6988306795909656))\n",
            "CCA coefficients mean non-concern: (np.float64(0.7234418000633571), np.float64(0.7234418000633571))\n",
            "Linear CKA concern: 0.9996418213263213\n",
            "Linear CKA non-concern: 0.5965399242544945\n",
            "Kernel CKA concern: 0.9980527931964092\n",
            "Kernel CKA non-concern: 0.7469800312902515\n",
            "Evaluate the pruned model 1\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f73daa2ac5b149388a504fb9ce35857a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 2.2328\n",
            "Precision: 0.1992, Recall: 0.1531, F1-Score: 0.1028\n",
            "              precision    recall  f1-score   support\n",
            "           0       0.00      0.00      0.00       980\n",
            "           1       0.12      1.00      0.21      1135\n",
            "           2       0.00      0.00      0.00      1032\n",
            "           3       0.00      0.00      0.00      1010\n",
            "           4       0.00      0.00      0.00       982\n",
            "           5       0.00      0.00      0.00       892\n",
            "           6       1.00      0.36      0.53       958\n",
            "           7       0.00      0.00      0.00      1028\n",
            "           8       0.87      0.17      0.28       974\n",
            "           9       0.00      0.00      0.00      1009\n",
            "    accuracy                           0.16     10000\n",
            "   macro avg       0.20      0.15      0.10     10000\n",
            "weighted avg       0.19      0.16      0.10     10000\n",
            "adding eps to diagonal and taking inverse\n",
            "taking square root\n",
            "dot products...\n",
            "trying to take final svd\n",
            "computed everything!\n",
            "adding eps to diagonal and taking inverse\n",
            "taking square root\n",
            "dot products...\n",
            "trying to take final svd\n",
            "computed everything!\n",
            "CCA coefficients mean concern: (np.float64(0.6414379712886926), np.float64(0.6414379712886926))\n",
            "CCA coefficients mean non-concern: (np.float64(0.7278117740890336), np.float64(0.7278117740890336))\n",
            "Linear CKA concern: 0.9986126433477239\n",
            "Linear CKA non-concern: 0.45734858442950155\n",
            "Kernel CKA concern: 0.9954215317542231\n",
            "Kernel CKA non-concern: 0.6233939088579237\n",
            "Evaluate the pruned model 2\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "47d41c87c22c489399dc247e650bbbd5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 2.9500\n",
            "Precision: 0.0826, Recall: 0.1644, F1-Score: 0.0880\n",
            "              precision    recall  f1-score   support\n",
            "           0       0.00      0.00      0.00       980\n",
            "           1       0.00      0.00      0.00      1135\n",
            "           2       0.11      1.00      0.20      1032\n",
            "           3       0.71      0.64      0.68      1010\n",
            "           4       0.00      0.00      0.00       982\n",
            "           5       0.00      0.00      0.00       892\n",
            "           6       0.00      0.00      0.00       958\n",
            "           7       0.00      0.00      0.00      1028\n",
            "           8       0.00      0.00      0.00       974\n",
            "           9       0.00      0.00      0.00      1009\n",
            "    accuracy                           0.17     10000\n",
            "   macro avg       0.08      0.16      0.09     10000\n",
            "weighted avg       0.08      0.17      0.09     10000\n",
            "adding eps to diagonal and taking inverse\n",
            "taking square root\n",
            "dot products...\n",
            "trying to take final svd\n",
            "computed everything!\n",
            "adding eps to diagonal and taking inverse\n",
            "taking square root\n",
            "dot products...\n",
            "trying to take final svd\n",
            "computed everything!\n",
            "CCA coefficients mean concern: (np.float64(0.6066448024374764), np.float64(0.6066448024374764))\n",
            "CCA coefficients mean non-concern: (np.float64(0.7015759043729664), np.float64(0.7015759043729664))\n",
            "Linear CKA concern: 0.9983874076988621\n",
            "Linear CKA non-concern: 0.2703890457069119\n",
            "Kernel CKA concern: 0.9953028552915643\n",
            "Kernel CKA non-concern: 0.43683296049727094\n",
            "Evaluate the pruned model 3\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "41b58405727648419c58e52aa1c9cef8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 2.2158\n",
            "Precision: 0.5103, Recall: 0.1242, F1-Score: 0.0614\n",
            "              precision    recall  f1-score   support\n",
            "           0       1.00      0.01      0.01       980\n",
            "           1       0.00      0.00      0.00      1135\n",
            "           2       1.00      0.06      0.10      1032\n",
            "           3       0.10      1.00      0.19      1010\n",
            "           4       0.00      0.00      0.00       982\n",
            "           5       1.00      0.00      0.00       892\n",
            "           6       1.00      0.00      0.01       958\n",
            "           7       0.00      0.00      0.00      1028\n",
            "           8       1.00      0.18      0.30       974\n",
            "           9       0.00      0.00      0.00      1009\n",
            "    accuracy                           0.12     10000\n",
            "   macro avg       0.51      0.12      0.06     10000\n",
            "weighted avg       0.49      0.12      0.06     10000\n",
            "adding eps to diagonal and taking inverse\n",
            "taking square root\n",
            "dot products...\n",
            "trying to take final svd\n",
            "computed everything!\n",
            "adding eps to diagonal and taking inverse\n",
            "taking square root\n",
            "dot products...\n",
            "trying to take final svd\n",
            "computed everything!\n",
            "CCA coefficients mean concern: (np.float64(0.5999859824837638), np.float64(0.5999859824837638))\n",
            "CCA coefficients mean non-concern: (np.float64(0.7631938651857216), np.float64(0.7631938651857216))\n",
            "Linear CKA concern: 0.9998151145456614\n",
            "Linear CKA non-concern: 0.3040216591819608\n",
            "Kernel CKA concern: 0.9994734925877145\n",
            "Kernel CKA non-concern: 0.49404925697686486\n",
            "Evaluate the pruned model 4\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d4f3e9294955411bb6a1cdb7a2f707db",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 2.7934\n",
            "Precision: 0.0099, Recall: 0.1000, F1-Score: 0.0180\n",
            "              precision    recall  f1-score   support\n",
            "           0       0.00      0.00      0.00       980\n",
            "           1       0.00      0.00      0.00      1135\n",
            "           2       0.00      0.00      0.00      1032\n",
            "           3       0.00      0.00      0.00      1010\n",
            "           4       0.10      1.00      0.18       982\n",
            "           5       0.00      0.00      0.00       892\n",
            "           6       0.00      0.00      0.00       958\n",
            "           7       0.00      0.00      0.00      1028\n",
            "           8       0.00      0.00      0.00       974\n",
            "           9       0.00      0.00      0.00      1009\n",
            "    accuracy                           0.10     10000\n",
            "   macro avg       0.01      0.10      0.02     10000\n",
            "weighted avg       0.01      0.10      0.02     10000\n",
            "adding eps to diagonal and taking inverse\n",
            "taking square root\n",
            "dot products...\n",
            "trying to take final svd\n",
            "computed everything!\n",
            "adding eps to diagonal and taking inverse\n",
            "taking square root\n",
            "dot products...\n",
            "trying to take final svd\n",
            "computed everything!\n",
            "CCA coefficients mean concern: (np.float64(0.5980553210450054), np.float64(0.5980553210450054))\n",
            "CCA coefficients mean non-concern: (np.float64(0.7240029454036838), np.float64(0.7240029454036838))\n",
            "Linear CKA concern: 0.9941307799234008\n",
            "Linear CKA non-concern: 0.3007401543732985\n",
            "Kernel CKA concern: 0.9833149693775209\n",
            "Kernel CKA non-concern: 0.45155979646001704\n"
          ]
        }
      ],
      "source": [
        "for concern in range(5):\n",
        "    train = copy.deepcopy(train_dataloader)\n",
        "    valid = copy.deepcopy(valid_dataloader)\n",
        "    positive_samples = SamplingDataset(\n",
        "        train,\n",
        "        concern,\n",
        "        num_samples,\n",
        "        num_classes,\n",
        "        True,\n",
        "        4,\n",
        "        device=device,\n",
        "        resample=False,\n",
        "    )\n",
        "    negative_samples = SamplingDataset(\n",
        "        train,\n",
        "        concern,\n",
        "        num_samples,\n",
        "        num_classes,\n",
        "        False,\n",
        "        4,\n",
        "        device=device,\n",
        "        resample=False,\n",
        "    )\n",
        "    all_samples = SamplingDataset(\n",
        "        train,\n",
        "        200,\n",
        "        num_samples,\n",
        "        num_classes,\n",
        "        False,\n",
        "        4,\n",
        "        device=device,\n",
        "        resample=False,\n",
        "    )\n",
        "\n",
        "    module = copy.deepcopy(model)\n",
        "\n",
        "    prune_wanda(\n",
        "        module,\n",
        "        config,\n",
        "        positive_samples,\n",
        "        sparsity_ratio=0.3,\n",
        "        include_layers=None,\n",
        "        exclude_layers=None,\n",
        "    )\n",
        "\n",
        "    print(f\"Evaluate the pruned model {concern}\")\n",
        "    result = evaluate_model(module, config, test_dataloader, verbose=True)\n",
        "    get_sparsity(module)\n",
        "\n",
        "    get_similarity(\n",
        "        model, module, valid, concern, num_samples, num_classes, config, seed=seed\n",
        "    )"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "DecomposeTransformer",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}