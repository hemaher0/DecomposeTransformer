{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "sys.path.append(\"../../../\")\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import copy\n",
        "import torch\n",
        "from datetime import datetime\n",
        "from src.utils.helper import Config, color_print\n",
        "from src.utils.load import save_checkpoint\n",
        "from src.utils.load import load_model, load_data, save_checkpoint\n",
        "from src.models.evaluate import evaluate_model, get_sparsity, get_similarity\n",
        "from src.utils.sampling import SamplingDataset\n",
        "from src.pruning.prune_head import head_importance_prunning\n",
        "from src.pruning.prune import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "input_size = 28 * 28\n",
        "num_classes = 10\n",
        "num_epochs = 5\n",
        "batch_size = 100\n",
        "learning_rate = 0.001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "name = \"MNIST\"\n",
        "device = torch.device(\"cuda:0\")\n",
        "checkpoint = None\n",
        "batch_size = 16\n",
        "num_workers = 4\n",
        "num_samples = 128\n",
        "ci_ratio = 0.3\n",
        "seed = 44"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SimpleDNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleDNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(784, 512)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256, 128)\n",
        "        self.fc4 = nn.Linear(128, 64)\n",
        "        self.fc5 = nn.Linear(64, 32)\n",
        "        self.fc6 = nn.Linear(32, 10)\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "        self.bn1 = nn.BatchNorm1d(512)\n",
        "        self.bn2 = nn.BatchNorm1d(256)\n",
        "        self.bn3 = nn.BatchNorm1d(128)\n",
        "        self.bn4 = nn.BatchNorm1d(64)\n",
        "        self.bn5 = nn.BatchNorm1d(32)\n",
        "\n",
        "    def forward(self, x, output_hidden_states=False):\n",
        "        hidden_states = []\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        x = self.bn1(self.fc1(x))\n",
        "        if output_hidden_states:\n",
        "            hidden_states.append(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.bn2(self.fc2(x))\n",
        "        if output_hidden_states:\n",
        "            hidden_states.append(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.bn3(self.fc3(x))\n",
        "        if output_hidden_states:\n",
        "            hidden_states.append(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.bn4(self.fc4(x))\n",
        "        if output_hidden_states:\n",
        "            hidden_states.append(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.bn5(self.fc5(x))\n",
        "        if output_hidden_states:\n",
        "            hidden_states.append(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.fc6(x)\n",
        "        if output_hidden_states:\n",
        "            hidden_states.append(x)\n",
        "\n",
        "        if output_hidden_states:\n",
        "            return {\"logits\": x, \"hidden_states\": hidden_states}\n",
        "        else:\n",
        "            return {\"logits\": x}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = SimpleDNN()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SimpleDNN(\n",
              "  (fc1): Linear(in_features=784, out_features=512, bias=True)\n",
              "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
              "  (fc3): Linear(in_features=256, out_features=128, bias=True)\n",
              "  (fc4): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (fc5): Linear(in_features=64, out_features=32, bias=True)\n",
              "  (fc6): Linear(in_features=32, out_features=10, bias=True)\n",
              "  (relu): ReLU()\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              "  (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (bn3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (bn4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (bn5): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              ")"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "config = Config(name, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading cached dataset MNIST.\n",
            "train.pkl is loaded from cache.\n",
            "valid.pkl is loaded from cache.\n",
            "test.pkl is loaded from cache.\n",
            "The dataset MNIST is loaded\n",
            "{'dataset_name': 'MNIST', 'path': 'ylecun/mnist', 'config_name': 'mnist', 'features': {'first_column': 'image', 'second_column': 'label'}, 'cache_dir': 'Datasets/MNIST', 'task_type': 'image_classification'}\n"
          ]
        }
      ],
      "source": [
        "train_dataloader, valid_dataloader, test_dataloader = load_data(\n",
        "    config,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=num_workers,\n",
        "    do_cache=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# for epoch in range(num_epochs):\n",
        "#     for i, batch in enumerate(train_dataloader):\n",
        "#         images = batch[\"image\"].float()\n",
        "#         labels = batch[\"labels\"]\n",
        "#         # Forward pass\n",
        "#         outputs = model(images)\n",
        "#         logits = outputs[\"logits\"]\n",
        "#         loss = criterion(logits, labels)\n",
        "\n",
        "#         # Backward and optimize\n",
        "#         optimizer.zero_grad()\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "\n",
        "#         if (i + 1) % 100 == 0:\n",
        "#             print(\n",
        "#                 f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_dataloader)}], Loss: {loss.item():.4f}\"\n",
        "#             )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# torch.save(model.state_dict(), \"Models/MNIST/model.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = SimpleDNN()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.load_state_dict(torch.load(\"Models/MNIST/model.pt\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "34e070a81ed94f99b455357a026cfed2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 0.1288\n",
            "Precision: 0.9671, Recall: 0.9669, F1-Score: 0.9669\n",
            "              precision    recall  f1-score   support\n",
            "           0       0.98      0.99      0.98       980\n",
            "           1       0.98      0.99      0.98      1135\n",
            "           2       0.97      0.97      0.97      1032\n",
            "           3       0.95      0.98      0.96      1010\n",
            "           4       0.97      0.96      0.96       982\n",
            "           5       0.96      0.96      0.96       892\n",
            "           6       0.97      0.97      0.97       958\n",
            "           7       0.97      0.96      0.96      1028\n",
            "           8       0.97      0.96      0.96       974\n",
            "           9       0.95      0.94      0.95      1009\n",
            "    accuracy                           0.97     10000\n",
            "   macro avg       0.97      0.97      0.97     10000\n",
            "weighted avg       0.97      0.97      0.97     10000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "result = evaluate_model(model, config, test_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluate the pruned model 0\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d85846b3386247bcb39274bd00bce62d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 5.9494\n",
            "Precision: 0.0098, Recall: 0.1000, F1-Score: 0.0179\n",
            "              precision    recall  f1-score   support\n",
            "           0       0.10      1.00      0.18       980\n",
            "           1       0.00      0.00      0.00      1135\n",
            "           2       0.00      0.00      0.00      1032\n",
            "           3       0.00      0.00      0.00      1010\n",
            "           4       0.00      0.00      0.00       982\n",
            "           5       0.00      0.00      0.00       892\n",
            "           6       0.00      0.00      0.00       958\n",
            "           7       0.00      0.00      0.00      1028\n",
            "           8       0.00      0.00      0.00       974\n",
            "           9       0.00      0.00      0.00      1009\n",
            "    accuracy                           0.10     10000\n",
            "   macro avg       0.01      0.10      0.02     10000\n",
            "weighted avg       0.01      0.10      0.02     10000\n",
            "adding eps to diagonal and taking inverse\n",
            "taking square root\n",
            "dot products...\n",
            "trying to take final svd\n",
            "computed everything!\n",
            "adding eps to diagonal and taking inverse\n",
            "taking square root\n",
            "dot products...\n",
            "trying to take final svd\n",
            "computed everything!\n",
            "CCA coefficients mean concern: (np.float64(0.5589453541226514), np.float64(0.5589453541226514))\n",
            "CCA coefficients mean non-concern: (np.float64(0.4877951967490529), np.float64(0.4877951967490529))\n",
            "Linear CKA concern: 0.9953947227362107\n",
            "Linear CKA non-concern: 0.44582311280208864\n",
            "Kernel CKA concern: 0.9834681210942123\n",
            "Kernel CKA non-concern: 0.43471245137745956\n",
            "Evaluate the pruned model 1\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3bc2015c7a7b4ce9b9741e6bbbd49f78",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 4.6475\n",
            "Precision: 0.0114, Recall: 0.1000, F1-Score: 0.0204\n",
            "              precision    recall  f1-score   support\n",
            "           0       0.00      0.00      0.00       980\n",
            "           1       0.11      1.00      0.20      1135\n",
            "           2       0.00      0.00      0.00      1032\n",
            "           3       0.00      0.00      0.00      1010\n",
            "           4       0.00      0.00      0.00       982\n",
            "           5       0.00      0.00      0.00       892\n",
            "           6       0.00      0.00      0.00       958\n",
            "           7       0.00      0.00      0.00      1028\n",
            "           8       0.00      0.00      0.00       974\n",
            "           9       0.00      0.00      0.00      1009\n",
            "    accuracy                           0.11     10000\n",
            "   macro avg       0.01      0.10      0.02     10000\n",
            "weighted avg       0.01      0.11      0.02     10000\n",
            "adding eps to diagonal and taking inverse\n",
            "taking square root\n",
            "dot products...\n",
            "trying to take final svd\n",
            "computed everything!\n",
            "adding eps to diagonal and taking inverse\n",
            "taking square root\n",
            "dot products...\n",
            "trying to take final svd\n",
            "computed everything!\n",
            "CCA coefficients mean concern: (np.float64(0.5123296149774118), np.float64(0.5123296149774118))\n",
            "CCA coefficients mean non-concern: (np.float64(0.5630794856783978), np.float64(0.5630794856783978))\n",
            "Linear CKA concern: 0.9997462366540599\n",
            "Linear CKA non-concern: 0.4193712822293419\n",
            "Kernel CKA concern: 0.9990317960113311\n",
            "Kernel CKA non-concern: 0.4762744987645207\n",
            "Evaluate the pruned model 2\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2cd0e11feff54cca88f2b08298733ab0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 4.5763\n",
            "Precision: 0.0103, Recall: 0.1000, F1-Score: 0.0187\n",
            "              precision    recall  f1-score   support\n",
            "           0       0.00      0.00      0.00       980\n",
            "           1       0.00      0.00      0.00      1135\n",
            "           2       0.10      1.00      0.19      1032\n",
            "           3       0.00      0.00      0.00      1010\n",
            "           4       0.00      0.00      0.00       982\n",
            "           5       0.00      0.00      0.00       892\n",
            "           6       0.00      0.00      0.00       958\n",
            "           7       0.00      0.00      0.00      1028\n",
            "           8       0.00      0.00      0.00       974\n",
            "           9       0.00      0.00      0.00      1009\n",
            "    accuracy                           0.10     10000\n",
            "   macro avg       0.01      0.10      0.02     10000\n",
            "weighted avg       0.01      0.10      0.02     10000\n",
            "adding eps to diagonal and taking inverse\n",
            "taking square root\n",
            "dot products...\n",
            "trying to take final svd\n",
            "computed everything!\n",
            "adding eps to diagonal and taking inverse\n",
            "taking square root\n",
            "dot products...\n",
            "trying to take final svd\n",
            "computed everything!\n",
            "CCA coefficients mean concern: (np.float64(0.502416433833518), np.float64(0.502416433833518))\n",
            "CCA coefficients mean non-concern: (np.float64(0.562076434830813), np.float64(0.562076434830813))\n",
            "Linear CKA concern: 0.9940815094581631\n",
            "Linear CKA non-concern: 0.1795294024082903\n",
            "Kernel CKA concern: 0.983573434056845\n",
            "Kernel CKA non-concern: 0.3192283511300618\n",
            "Evaluate the pruned model 3\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f537ee48143f479cbd35c45c565d5fe6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 4.4090\n",
            "Precision: 0.0101, Recall: 0.1000, F1-Score: 0.0183\n",
            "              precision    recall  f1-score   support\n",
            "           0       0.00      0.00      0.00       980\n",
            "           1       0.00      0.00      0.00      1135\n",
            "           2       0.00      0.00      0.00      1032\n",
            "           3       0.10      1.00      0.18      1010\n",
            "           4       0.00      0.00      0.00       982\n",
            "           5       0.00      0.00      0.00       892\n",
            "           6       0.00      0.00      0.00       958\n",
            "           7       0.00      0.00      0.00      1028\n",
            "           8       0.00      0.00      0.00       974\n",
            "           9       0.00      0.00      0.00      1009\n",
            "    accuracy                           0.10     10000\n",
            "   macro avg       0.01      0.10      0.02     10000\n",
            "weighted avg       0.01      0.10      0.02     10000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for concern in range(num_classes):\n",
        "    train = copy.deepcopy(train_dataloader)\n",
        "    valid = copy.deepcopy(valid_dataloader)\n",
        "    positive_samples = SamplingDataset(\n",
        "        train,\n",
        "        concern,\n",
        "        num_samples,\n",
        "        num_classes,\n",
        "        True,\n",
        "        4,\n",
        "        device=device,\n",
        "        resample=False,\n",
        "    )\n",
        "    negative_samples = SamplingDataset(\n",
        "        train,\n",
        "        concern,\n",
        "        num_samples,\n",
        "        num_classes,\n",
        "        False,\n",
        "        4,\n",
        "        device=device,\n",
        "        resample=False,\n",
        "    )\n",
        "    all_samples = SamplingDataset(\n",
        "        train,\n",
        "        200,\n",
        "        num_samples,\n",
        "        num_classes,\n",
        "        False,\n",
        "        4,\n",
        "        device=device,\n",
        "        resample=False,\n",
        "    )\n",
        "\n",
        "    module = copy.deepcopy(model)\n",
        "\n",
        "    prune_wanda(\n",
        "        module,\n",
        "        config,\n",
        "        positive_samples,\n",
        "        sparsity_ratio=0.6,\n",
        "        include_layers=None,\n",
        "        exclude_layers=None,\n",
        "    )\n",
        "\n",
        "    print(f\"Evaluate the pruned model {concern}\")\n",
        "    result = evaluate_model(module, config, test_dataloader, verbose=True)\n",
        "    get_sparsity(module)\n",
        "\n",
        "    get_similarity(\n",
        "        model, module, valid, concern, num_samples, num_classes, config, seed=seed\n",
        "    )"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "DecomposeTransformer",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}