{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sqeeze by rows and columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../../../../\")\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch\n",
    "from datetime import datetime\n",
    "from src.utils.helper import Config, color_print\n",
    "from src.utils.load import load_model, load_data, save_checkpoint, load_checkpoint\n",
    "from src.models.evaluate import evaluate_model, get_sparsity, get_similarity\n",
    "from src.utils.sampling import SamplingDataset\n",
    "from src.pruning.prune_head import head_importance_prunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name = \"bert-tiny-yahoo\"\n",
    "name = \"bert-4-128-yahoo\"\n",
    "device = torch.device(\"cuda:0\")\n",
    "checkpoint = None\n",
    "batch_size = 16\n",
    "num_workers = 4\n",
    "num_samples = 128\n",
    "ci_ratio = 0.3\n",
    "seed = 44"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(name, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'architectures': 'bert',\n",
      " 'dataset_name': 'YahooAnswersTopics',\n",
      " 'model_name': 'models/bert-4-128-yahoo',\n",
      " 'num_labels': 10,\n",
      " 'tokenizer_name': 'fabriceyhc/bert-base-uncased-yahoo_answers_topics'}\n"
     ]
    }
   ],
   "source": [
    "config.model_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the model.\n",
      "{'architectures': 'bert',\n",
      " 'dataset_name': 'YahooAnswersTopics',\n",
      " 'model_name': 'models/bert-4-128-yahoo',\n",
      " 'num_labels': 10,\n",
      " 'tokenizer_name': 'fabriceyhc/bert-base-uncased-yahoo_answers_topics'}\n",
      "The model models/bert-4-128-yahoo is loaded.\n"
     ]
    }
   ],
   "source": [
    "model = load_model(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cached dataset YahooAnswersTopics.\n",
      "train.pkl is loaded from cache.\n",
      "valid.pkl is loaded from cache.\n",
      "test.pkl is loaded from cache.\n",
      "The dataset YahooAnswersTopics is loaded\n",
      "{'config_name': 'yahoo_answers_topics',\n",
      " 'features': {'first_column': 'question_title', 'second_column': 'topic'},\n",
      " 'path': 'yahoo_answers_topics'}\n"
     ]
    }
   ],
   "source": [
    "train_dataloader, valid_dataloader, test_dataloader = load_data(\n",
    "    config,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    do_cache=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hook(method):\n",
    "    def hook(module, input, output):\n",
    "        method(module, input, output)\n",
    "\n",
    "    return hook\n",
    "\n",
    "\n",
    "def prune_concern_identification(\n",
    "    model,\n",
    "    model_config: Config,\n",
    "    dominant_concern: SamplingDataset,\n",
    "    non_dominant_concern: SamplingDataset,\n",
    "    sparsity_ratio: float = 0.6,\n",
    "    include_layers=None,\n",
    "    exclude_layers=None,\n",
    "    compress=False,\n",
    ") -> None:\n",
    "    layers = find_layers(\n",
    "        model, include_layers=include_layers, exclude_layers=exclude_layers\n",
    "    )\n",
    "    handle_list = []\n",
    "\n",
    "    method1 = Methods(sparsity_ratio, axis=1, compress=compress)\n",
    "    method2 = Methods(sparsity_ratio, axis=0, compress=compress)\n",
    "    for name, layer in layers.items():\n",
    "        if \"intermediate\" in name:\n",
    "            handle = layer.register_forward_hook(method1.ci)\n",
    "        else:\n",
    "            handle = layer.register_forward_hook(method2.ci)\n",
    "        handle_list.append(handle)\n",
    "\n",
    "    dominant_batches = list(dominant_concern)\n",
    "    non_dominant_batches = list(non_dominant_concern)\n",
    "\n",
    "    if len(dominant_batches) != len(non_dominant_batches):\n",
    "        raise ValueError(\n",
    "            \"Batch sizes of dominant_concern and non_dominant_concern does not match.\"\n",
    "        )\n",
    "\n",
    "    combined_batches = {}\n",
    "    keys = dominant_batches[0].keys()\n",
    "\n",
    "    for key in keys:\n",
    "        combined_batches[key] = torch.cat(\n",
    "            [batch[key] for batch in dominant_batches + non_dominant_batches]\n",
    "        )\n",
    "\n",
    "    combined_dataloader = [combined_batches]\n",
    "    from src.pruning.propagate import propagate\n",
    "\n",
    "    propagate(model, combined_dataloader, model_config)\n",
    "\n",
    "    for handle in handle_list:\n",
    "        handle.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_layers(\n",
    "    model,\n",
    "    layer_types=None,\n",
    "    include_layers=None,\n",
    "    exclude_layers=None,\n",
    "    prefix: str = \"\",\n",
    "):\n",
    "    if layer_types is None:\n",
    "        layer_types = [torch.nn.Linear]\n",
    "    if include_layers is None:\n",
    "        include_layers = []\n",
    "    if exclude_layers is None:\n",
    "        exclude_layers = []\n",
    "    layers_dict = {}\n",
    "\n",
    "    def recursive_find(module, prefix: str) -> None:\n",
    "        for name, layer in module.named_children():\n",
    "            layer_name = f\"{prefix}.{name}\" if prefix else name\n",
    "            if any(exclude in layer_name for exclude in exclude_layers):\n",
    "                continue\n",
    "            if include_layers and not any(\n",
    "                include in layer_name for include in include_layers\n",
    "            ):\n",
    "                if not any(isinstance(layer, t) for t in layer_types):\n",
    "                    recursive_find(layer, layer_name)\n",
    "                continue\n",
    "            if isinstance(layer, tuple(layer_types)):\n",
    "                layers_dict[layer_name] = layer\n",
    "            else:\n",
    "                recursive_find(layer, layer_name)\n",
    "\n",
    "    recursive_find(model, prefix)\n",
    "\n",
    "    return layers_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Methods:\n",
    "    def __init__(self, ratio: float, axis=1, compress=False) -> None:\n",
    "        self.ratio = ratio\n",
    "        self.axis = axis\n",
    "        self.compress = compress\n",
    "\n",
    "    def ci(self, layer, inputs, outputs):\n",
    "        current_weight = layer.weight.data\n",
    "        current_bias = layer.bias.data if layer.bias is not None else None\n",
    "        X = inputs[0]\n",
    "\n",
    "        batch_size = X.shape[0] // 2\n",
    "\n",
    "        concern_inputs, non_concern_inputs = (\n",
    "            X[:batch_size],\n",
    "            X[batch_size:],\n",
    "        )  # (batch_size, seq_dim, input_dim)\n",
    "\n",
    "        calc_norm = lambda tensors, dim: torch.norm(\n",
    "            tensors.reshape((-1, tensors.shape[-1])), dim=dim\n",
    "        )\n",
    "\n",
    "        concern_norm = calc_norm(concern_inputs, dim=0).reshape((1, -1))\n",
    "        non_concern_norm = calc_norm(non_concern_inputs, dim=0).reshape((1, -1))\n",
    "\n",
    "        cosine_similarity = torch.nn.functional.cosine_similarity(\n",
    "            concern_inputs.reshape((-1, concern_inputs.shape[-1])),\n",
    "            non_concern_inputs.reshape((-1, non_concern_inputs.shape[-1])),\n",
    "            dim=0,\n",
    "        ).reshape(1, -1)\n",
    "\n",
    "        sine_similarity = torch.sqrt(1 - cosine_similarity**2)\n",
    "        distance = torch.sqrt(concern_norm**2 + non_concern_norm**2)\n",
    "        coefficient = (\n",
    "            concern_norm\n",
    "            + sine_similarity * torch.abs(concern_norm + non_concern_norm) / distance\n",
    "        )\n",
    "\n",
    "        importance_score = torch.abs(current_weight) * torch.abs(coefficient)\n",
    "        W_mask = torch.zeros_like(importance_score) == 1\n",
    "        sort_res = torch.sort(importance_score, dim=self.axis, stable=True)\n",
    "        num_prune = int(importance_score.shape[self.axis] * self.ratio)\n",
    "\n",
    "        if self.axis == 0:\n",
    "            indices_to_prune = sort_res[1][:num_prune, :]\n",
    "        else:\n",
    "            indices_to_prune = sort_res[1][:, :num_prune]\n",
    "\n",
    "        W_mask.scatter_(self.axis, indices_to_prune, True)\n",
    "        current_weight[W_mask] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate the pruned model 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f976fec94f8b4166966a3927db02d633",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating the model:   0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate the pruned model 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd5815641ae94830b4ac96ee74df5d57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating the model:   0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate the pruned model 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc0952a6a3f346a787a6d1f40be11c85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating the model:   0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate the pruned model 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc03c2c38758477aa2ab3cb162c9c5e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating the model:   0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate the pruned model 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8d754962588454298e9e68ec8f13348",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating the model:   0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate the pruned model 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e6ba3090ba54354a6c7b18895aa981f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating the model:   0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate the pruned model 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17308514f17149499a79082eac3a40e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating the model:   0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate the pruned model 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9527017fa63e492ba0d437a5afe1aecf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating the model:   0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate the pruned model 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae8502f611a84f28b2f37318530e78b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating the model:   0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate the pruned model 9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c8ec34a5ffc498590a7d0ff8e619698",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating the model:   0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result_list = []\n",
    "\n",
    "for concern in range(config.num_labels):\n",
    "    config.init_seed()\n",
    "    positive_samples = SamplingDataset(\n",
    "        train_dataloader,\n",
    "        config,\n",
    "        concern,\n",
    "        num_samples,\n",
    "        True,\n",
    "        4,\n",
    "        resample=False,\n",
    "    )\n",
    "    negative_samples = SamplingDataset(\n",
    "        train_dataloader,\n",
    "        config,\n",
    "        concern,\n",
    "        num_samples,\n",
    "        False,\n",
    "        4,\n",
    "        resample=False,\n",
    "    )\n",
    "    all_samples = SamplingDataset(\n",
    "        train_dataloader,\n",
    "        config,\n",
    "        200,\n",
    "        num_samples,\n",
    "        False,\n",
    "        4,\n",
    "        resample=False,\n",
    "    )\n",
    "\n",
    "    module = copy.deepcopy(model)\n",
    "\n",
    "    prune_concern_identification(\n",
    "        module,\n",
    "        config,\n",
    "        positive_samples,\n",
    "        negative_samples,\n",
    "        include_layers=[\"intermediate\", \"output\"],\n",
    "        exclude_layers=[\"attention\"],\n",
    "        sparsity_ratio=0.5,\n",
    "        compress=True,\n",
    "    )\n",
    "\n",
    "    print(f\"Evaluate the pruned model {concern}\")\n",
    "    result = evaluate_model(module, config, test_dataloader, verbose=True)\n",
    "    result_list.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.helper import report_to_df, append_nth_row\n",
    "\n",
    "df_list = [report_to_df(df) for df in result_list]\n",
    "new_df = append_nth_row(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.5343</td>\n",
       "      <td>0.4916</td>\n",
       "      <td>0.5121</td>\n",
       "      <td>2992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.6981</td>\n",
       "      <td>0.4823</td>\n",
       "      <td>0.5705</td>\n",
       "      <td>2992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.7032</td>\n",
       "      <td>0.6119</td>\n",
       "      <td>0.6544</td>\n",
       "      <td>3012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.3449</td>\n",
       "      <td>0.6374</td>\n",
       "      <td>0.4476</td>\n",
       "      <td>2998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.7245</td>\n",
       "      <td>0.7750</td>\n",
       "      <td>0.7489</td>\n",
       "      <td>2973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.8462</td>\n",
       "      <td>0.7583</td>\n",
       "      <td>0.7999</td>\n",
       "      <td>3054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.6780</td>\n",
       "      <td>0.4039</td>\n",
       "      <td>0.5063</td>\n",
       "      <td>3003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.6226</td>\n",
       "      <td>0.6381</td>\n",
       "      <td>0.6303</td>\n",
       "      <td>3012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.5820</td>\n",
       "      <td>0.7197</td>\n",
       "      <td>0.6436</td>\n",
       "      <td>2982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.7545</td>\n",
       "      <td>0.6432</td>\n",
       "      <td>0.6944</td>\n",
       "      <td>2982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  class  precision  recall  f1-score  support\n",
       "0     0     0.5343  0.4916    0.5121     2992\n",
       "1     1     0.6981  0.4823    0.5705     2992\n",
       "2     2     0.7032  0.6119    0.6544     3012\n",
       "3     3     0.3449  0.6374    0.4476     2998\n",
       "4     4     0.7245  0.7750    0.7489     2973\n",
       "5     5     0.8462  0.7583    0.7999     3054\n",
       "6     6     0.6780  0.4039    0.5063     3003\n",
       "7     7     0.6226  0.6381    0.6303     3012\n",
       "8     8     0.5820  0.7197    0.6436     2982\n",
       "9     9     0.7545  0.6432    0.6944     2982"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c304dc1327d64da4818c39574ae885e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating the model:   0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.2240\n",
      "Precision: 0.6478, Recall: 0.6149, F1-Score: 0.6195\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5321    0.4843    0.5071      2992\n",
      "           1     0.7005    0.4723    0.5642      2992\n",
      "           2     0.6957    0.6119    0.6511      3012\n",
      "           3     0.3443    0.6421    0.4482      2998\n",
      "           4     0.7254    0.7783    0.7509      2973\n",
      "           5     0.8403    0.7600    0.7981      3054\n",
      "           6     0.6719    0.4106    0.5097      3003\n",
      "           7     0.6185    0.6384    0.6283      3012\n",
      "           8     0.5854    0.7146    0.6436      2982\n",
      "           9     0.7637    0.6362    0.6941      2982\n",
      "\n",
      "    accuracy                         0.6150     30000\n",
      "   macro avg     0.6478    0.6149    0.6195     30000\n",
      "weighted avg     0.6481    0.6150    0.6198     30000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = evaluate_model(model, config, test_dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "decomposetransformer-UESb9BbT-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
