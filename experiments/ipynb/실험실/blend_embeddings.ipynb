{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../../../\")\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch\n",
    "from datetime import datetime\n",
    "from src.utils.helper import Config, color_print\n",
    "from src.utils.load import load_model, load_data, save_checkpoint, load_checkpoint\n",
    "from src.models.evaluate import evaluate_model, get_sparsity, get_similarity\n",
    "from src.utils.sampling import SamplingDataset\n",
    "from src.pruning.prune_head import head_importance_prunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name = \"bert-4-128-yahoo\"\n",
    "name = \"OSDG\"\n",
    "device = torch.device(\"cuda:0\")\n",
    "checkpoint = None\n",
    "batch_size = 16\n",
    "num_workers = 4\n",
    "num_samples = 128\n",
    "ci_ratio = 0.3\n",
    "seed = 44"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(name, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the model.\n",
      "{'architectures': 'bert',\n",
      " 'dataset_name': 'OSDG',\n",
      " 'model_name': 'sadickam/sdg-classification-bert',\n",
      " 'num_labels': 16,\n",
      " 'tokenizer_name': 'sadickam/sdg-classification-bert'}\n",
      "The model sadickam/sdg-classification-bert is loaded.\n"
     ]
    }
   ],
   "source": [
    "model = load_model(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=16, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cached dataset OSDG.\n",
      "train.pkl is loaded from cache.\n",
      "valid.pkl is loaded from cache.\n",
      "test.pkl is loaded from cache.\n",
      "The dataset OSDG is loaded\n",
      "{'config_name': '2024-01-01',\n",
      " 'features': {'first_column': 'text', 'second_column': 'labels'},\n",
      " 'path': 'albertmartinez/OSDG'}\n"
     ]
    }
   ],
   "source": [
    "train_dataloader, valid_dataloader, test_dataloader = load_data(\n",
    "    config,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    do_cache=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_samples = SamplingDataset(\n",
    "    train_dataloader,\n",
    "    config,\n",
    "    0,\n",
    "    num_samples,\n",
    "    True,\n",
    "    4,\n",
    "    resample=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_samples = SamplingDataset(\n",
    "    train_dataloader,\n",
    "    config,\n",
    "    0,\n",
    "    num_samples,\n",
    "    False,\n",
    "    4,\n",
    "    resample=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from scipy.stats import norm\n",
    "from typing import *\n",
    "from torch import Tensor\n",
    "from torch.nn import Module\n",
    "import torch.nn.functional as F\n",
    "from functools import partial\n",
    "from src.utils.sampling import SamplingDataset\n",
    "from src.pruning.propagate import propagate\n",
    "from src.utils.helper import Config\n",
    "import gc\n",
    "\n",
    "\n",
    "class Methods:\n",
    "    def __init__(\n",
    "        self, ratio: float, keep_dim, axis: int = 0, method=\"unstructed\"\n",
    "    ) -> None:\n",
    "        self.ratio = ratio\n",
    "        self.axis = axis\n",
    "        self.coefficient = None\n",
    "        self.keep_dim = keep_dim\n",
    "        self.method = method\n",
    "\n",
    "    def ci(self, layer, inputs, outputs):\n",
    "        current_weight = layer.weight.data.clone()\n",
    "        current_bias = layer.bias.data.clone() if layer.bias is not None else None\n",
    "\n",
    "        X = inputs[0]\n",
    "        batch_size = X.shape[0] // 2\n",
    "\n",
    "        concern_inputs, non_concern_inputs = (\n",
    "            X[:batch_size],\n",
    "            X[batch_size:],\n",
    "        )  # (batch_size, seq_dim, input_dim)\n",
    "\n",
    "        calc_norm = lambda tensors: torch.norm(\n",
    "            tensors.reshape(-1, tensors.shape[-1]), dim=0\n",
    "        )\n",
    "\n",
    "        concern_norm = calc_norm(concern_inputs).reshape(1, -1)\n",
    "        non_concern_norm = calc_norm(non_concern_inputs).reshape(1, -1)\n",
    "\n",
    "        cosine_similarity = F.cosine_similarity(\n",
    "            concern_inputs.reshape(-1, concern_inputs.shape[-1]),\n",
    "            non_concern_inputs.reshape(-1, non_concern_inputs.shape[-1]),\n",
    "            dim=0,\n",
    "        ).reshape(1, -1)\n",
    "\n",
    "        sine_similarity = torch.sqrt(1 - cosine_similarity**2 + 1e-8)\n",
    "        distance = torch.sqrt(concern_norm**2 + non_concern_norm**2 + 1e-8)\n",
    "        coefficient = (\n",
    "            concern_norm\n",
    "            + sine_similarity * torch.abs(concern_norm + non_concern_norm) / distance\n",
    "        )\n",
    "\n",
    "        concern_mean = concern_inputs.mean(dim=(0, 1))\n",
    "        concern_var = concern_inputs.var(dim=(0, 1)) + 1e-8\n",
    "\n",
    "        non_concern_mean = non_concern_inputs.mean(dim=(0, 1))\n",
    "        non_concern_var = non_concern_inputs.var(dim=(0, 1)) + 1e-8\n",
    "\n",
    "        fisher_score = (concern_mean - non_concern_mean) ** 2 / (\n",
    "            concern_var + non_concern_var\n",
    "        )\n",
    "        fisher_score = fisher_score / (fisher_score.max() + 1e-8)\n",
    "        fisher_score = fisher_score.reshape(1, -1)\n",
    "        coefficient = coefficient * (1 + fisher_score)\n",
    "\n",
    "        importance_score = torch.abs(current_weight) * torch.abs(coefficient)\n",
    "\n",
    "        # cosine_similarity = F.cosine_similarity(\n",
    "        #     concern_inputs.reshape((-1, concern_inputs.shape[-1])),\n",
    "        #     non_concern_inputs.reshape((-1, non_concern_inputs.shape[-1])),\n",
    "        #     dim=0,\n",
    "        # ).reshape(1, -1)\n",
    "\n",
    "        # sine_similarity = torch.sqrt(1 - cosine_similarity**2)\n",
    "        # distance = torch.sqrt(concern_norm**2 + non_concern_norm**2)\n",
    "        # coefficient = (\n",
    "        #     concern_norm\n",
    "        #     + sine_similarity * torch.abs(concern_norm + non_concern_norm) / distance\n",
    "        # )\n",
    "        num_prune = int(current_weight.shape[self.axis] * self.ratio)\n",
    "        # importance_score = torch.abs(current_weight)\n",
    "        # importance_score = torch.abs(current_weight) * torch.abs(coefficient)\n",
    "        # importance_score = torch.abs(current_weight) * torch.abs(torch.tensor(Vt1[0]/Vt2[-1], dtype=current_weight.dtype).to(current_weight.device).reshape(1, -1))\n",
    "\n",
    "        # print(current_weight.shape)\n",
    "        # print(coefficient.shape)\n",
    "        # print(self.coefficient.shape)\n",
    "\n",
    "        if self.method == \"unstructed\":\n",
    "            W_mask = torch.zeros_like(importance_score, dtype=bool)\n",
    "\n",
    "            sort_res = torch.sort(importance_score, dim=self.axis, stable=True)\n",
    "            if self.axis == 0:\n",
    "                indices_to_prune = sort_res[1][:num_prune, :]\n",
    "            else:\n",
    "                indices_to_prune = sort_res[1][:, :num_prune]\n",
    "\n",
    "            W_mask.scatter_(self.axis, indices_to_prune, True)\n",
    "            current_weight[W_mask] = 0\n",
    "        # elif self.method == \"structed\":\n",
    "        #     if self.axis == 0:\n",
    "        #         # importance_vector = torch.mean(importance_score, dim=1)\n",
    "        #         # importance_vector =  torch.mean(current_weight, dim=1)\n",
    "        #         importance_vector = torch.mean(importance_score, dim=1)\n",
    "\n",
    "        #     else:\n",
    "        #         # importance_vector = torch.mean(importance_score, dim=0)\n",
    "        #         # importance_vector =  torch.mean(current_weight, dim=0)\n",
    "        #         importance_vector = torch.mean(importance_score, dim=0)\n",
    "        #     sort_res = torch.sort(importance_vector)\n",
    "        #     indices_to_prune = sort_res[1][:num_prune]\n",
    "\n",
    "        #     if self.axis == 0:\n",
    "        #         current_weight[indices_to_prune, :] = 0\n",
    "        #     else:\n",
    "        #         current_weight[:, indices_to_prune] = 0\n",
    "        # else:\n",
    "        #     raise NotImplementedError(f\"{self.method} is not implemented\")\n",
    "\n",
    "        # pruned_list = indices_to_prune.tolist()\n",
    "        # pruned_list = sorted(pruned_list)\n",
    "        # print(f\"{self.axis}: {pruned_list}\")\n",
    "        # if not self.keep_dim:\n",
    "        #     if self.axis == 0:\n",
    "        #         slice_mask = ~torch.any(current_weight, dim=1)\n",
    "        #         current_weight = current_weight[slice_mask, :].clone()\n",
    "        #         if current_bias is not None:\n",
    "        #             current_bias = current_bias[slice_mask].clone()\n",
    "        #     else:\n",
    "        #         slice_mask = ~torch.any(current_weight, dim=0)\n",
    "        #         current_weight = current_weight[:, slice_mask].clone()\n",
    "\n",
    "        layer.weight.data = current_weight\n",
    "        layer.bias.data = current_bias\n",
    "        layer.in_features = current_weight.shape[1]\n",
    "        layer.out_features = current_weight.shape[0]\n",
    "\n",
    "\n",
    "def find_layers(\n",
    "    model: Module,\n",
    "    layer_types: Optional[List[Type[Module]]] = None,\n",
    "    include_layers: Optional[List[str]] = None,\n",
    "    exclude_layers: Optional[List[str]] = None,\n",
    "    prefix: str = \"\",\n",
    ") -> Dict[str, Module]:\n",
    "    if layer_types is None:\n",
    "        layer_types = [nn.Linear]\n",
    "    if include_layers is None:\n",
    "        include_layers = []\n",
    "    if exclude_layers is None:\n",
    "        exclude_layers = []\n",
    "    layers_dict: Dict[str, Module] = {}\n",
    "\n",
    "    def recursive_find(module: Module, prefix: str) -> None:\n",
    "        for name, layer in module.named_children():\n",
    "            layer_name = f\"{prefix}.{name}\" if prefix else name\n",
    "            if any(exclude in layer_name for exclude in exclude_layers):\n",
    "                continue\n",
    "            if include_layers and not any(\n",
    "                include in layer_name for include in include_layers\n",
    "            ):\n",
    "                if not any(isinstance(layer, t) for t in layer_types):\n",
    "                    recursive_find(layer, layer_name)\n",
    "                continue\n",
    "            if isinstance(layer, tuple(layer_types)):\n",
    "                layers_dict[layer_name] = layer\n",
    "            else:\n",
    "                recursive_find(layer, layer_name)\n",
    "\n",
    "    recursive_find(model, prefix)\n",
    "\n",
    "    return layers_dict\n",
    "\n",
    "\n",
    "def get_hook(method):\n",
    "    def hook(module, input, output):\n",
    "        method(module, input, output)\n",
    "\n",
    "    return hook\n",
    "\n",
    "\n",
    "def get_embeddings(model, dataloader):\n",
    "    embeddings_list = {\"embeddings\": [], \"labels\": [], \"attention_mask\": []}\n",
    "\n",
    "    for batch in dataloader:\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        labels = batch[\"labels\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        with torch.no_grad():\n",
    "            input_embeddings = model.get_input_embeddings()(input_ids)\n",
    "        embeddings_list[\"embeddings\"].append(input_embeddings)\n",
    "        embeddings_list[\"labels\"].append(labels)\n",
    "        embeddings_list[\"attention_mask\"].append(attention_mask)\n",
    "        from src.utils.data_class import CustomEmbeddingDataset\n",
    "    return CustomEmbeddingDataset(embeddings_list)\n",
    "\n",
    "\n",
    "def calc_svd(tensor1, tensor2):\n",
    "    flatten_tensor1 = tensor1.reshape(-1, tensor1.shape[-1]).detach().cpu()\n",
    "    flatten_tensor2 = tensor2.reshape(-1, tensor2.shape[-1]).detach().cpu()\n",
    "    product = flatten_tensor1.T @ flatten_tensor2\n",
    "    import numpy as np\n",
    "\n",
    "    U, sv, Vt = np.linalg.svd(product)\n",
    "    normalized_U = U / np.linalg.norm(U, axis=0)\n",
    "    normalized_sv = sv / np.linalg.norm(sv)\n",
    "    normalized_Vt = Vt / np.linalg.norm(Vt, axis=1)\n",
    "    return normalized_U, normalized_sv, normalized_Vt\n",
    "\n",
    "\n",
    "def prune_concern_identification(\n",
    "    model: Module,\n",
    "    config: Config,\n",
    "    dominant_concern: SamplingDataset,\n",
    "    non_dominant_concern: SamplingDataset,\n",
    "    sparsity_ratio: float = 0.6,\n",
    "    include_layers: Optional[List[str]] = None,\n",
    "    exclude_layers: Optional[List[str]] = None,\n",
    "    method=\"unstructed\",\n",
    "    keep_dim=True,\n",
    ") -> None:\n",
    "    layers = find_layers(\n",
    "        model, include_layers=include_layers, exclude_layers=exclude_layers\n",
    "    )\n",
    "    handle_list = []\n",
    "\n",
    "    method1 = Methods(sparsity_ratio, axis=0, method=method, keep_dim=keep_dim)\n",
    "    method2 = Methods(sparsity_ratio, axis=1, method=method, keep_dim=keep_dim)\n",
    "\n",
    "    for name, layer in layers.items():\n",
    "        if \"intermediate\" in name:\n",
    "            handle = layer.register_forward_hook(method1.ci)\n",
    "        else:\n",
    "            handle = layer.register_forward_hook(method2.ci)\n",
    "        handle_list.append(handle)\n",
    "\n",
    "    pos_embeddings = get_embeddings(model, dominant_concern)\n",
    "    neg_embeddings = get_embeddings(model, non_dominant_concern)\n",
    "    dominant_batches = list(pos_embeddings)\n",
    "    non_dominant_batches = list(neg_embeddings)\n",
    "    combined_batches = {}\n",
    "    keys = dominant_batches[0].keys()\n",
    "    for key in keys:\n",
    "        combined_batches[key] = torch.cat(\n",
    "            [batch[key] for batch in dominant_batches + non_dominant_batches]\n",
    "        )\n",
    "\n",
    "    combined_dataloader = [combined_batches]\n",
    "    method1.coefficient = calc_coefficient(combined_dataloader, dim=1)\n",
    "    method2.coefficient = calc_coefficient(combined_dataloader, dim=0)\n",
    "    propagate(model, combined_dataloader, config)\n",
    "\n",
    "    for handle in handle_list:\n",
    "        handle.remove()\n",
    "\n",
    "\n",
    "def calc_coefficient(combined_dataloader, dim=0):\n",
    "    embeddings = combined_dataloader[0][\"embeddings\"]\n",
    "\n",
    "    batch_size = embeddings.shape[0] // 2\n",
    "    concern_inputs, non_concern_inputs = (\n",
    "        embeddings[:batch_size],\n",
    "        embeddings[batch_size:],\n",
    "    )\n",
    "\n",
    "    return concern_inputs, non_concern_inputs\n",
    "    # calc_norm = lambda tensors, dim: torch.norm(\n",
    "    #     tensors.reshape((-1, tensors.shape[-1])), dim=dim\n",
    "    # )\n",
    "\n",
    "    # if dim == 0:\n",
    "    #     new_shape = (-1, 1)\n",
    "    # else:\n",
    "    #     new_shape = (1, -1)\n",
    "\n",
    "    # concern_norm = calc_norm(concern_inputs, dim=0).reshape(new_shape)\n",
    "    # non_concern_norm = calc_norm(non_concern_inputs, dim=0).reshape(new_shape)\n",
    "\n",
    "    # cosine_similarity = F.cosine_similarity(\n",
    "    #     concern_inputs.reshape((-1, concern_inputs.shape[-1])),\n",
    "    #     non_concern_inputs.reshape((-1, non_concern_inputs.shape[-1])),\n",
    "    #     dim=0,\n",
    "    # ).reshape(new_shape)\n",
    "\n",
    "    # sine_similarity = torch.sign(cosine_similarity) * torch.sqrt(\n",
    "    #     1 - cosine_similarity**2\n",
    "    # )\n",
    "    # euclidean_distance = torch.sqrt(concern_norm**2 + non_concern_norm**2)\n",
    "    # coefficient = (\n",
    "    #     concern_norm\n",
    "    #     + sine_similarity\n",
    "    #     * torch.abs(concern_norm + non_concern_norm)\n",
    "    #     / euclidean_distance\n",
    "    # )\n",
    "    # return coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate the pruned model 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "998d21fb574c466da482e34faaa063cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating the model:   0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.9374\n",
      "Precision: 0.7739, Recall: 0.7771, F1-Score: 0.7712\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7504    0.6562    0.7001       797\n",
      "           1     0.8424    0.6968    0.7627       775\n",
      "           2     0.8686    0.8730    0.8708       795\n",
      "           3     0.8763    0.8108    0.8423      1110\n",
      "           4     0.8526    0.8032    0.8271      1260\n",
      "           5     0.8948    0.6848    0.7759       882\n",
      "           6     0.8480    0.8011    0.8239       940\n",
      "           7     0.4845    0.5603    0.5196       473\n",
      "           8     0.6835    0.8365    0.7523       746\n",
      "           9     0.5727    0.7373    0.6447       689\n",
      "          10     0.7101    0.7896    0.7477       670\n",
      "          11     0.6096    0.8109    0.6960       312\n",
      "          12     0.7114    0.8045    0.7551       665\n",
      "          13     0.8682    0.8185    0.8426       314\n",
      "          14     0.8512    0.7791    0.8135       756\n",
      "          15     0.9583    0.9720    0.9651      1607\n",
      "\n",
      "    accuracy                         0.7934     12791\n",
      "   macro avg     0.7739    0.7771    0.7712     12791\n",
      "weighted avg     0.8055    0.7934    0.7958     12791\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_list = []\n",
    "\n",
    "for concern in range(config.num_labels):\n",
    "    config.init_seed()\n",
    "    positive_samples = SamplingDataset(\n",
    "        train_dataloader,\n",
    "        config,\n",
    "        concern,\n",
    "        num_samples,\n",
    "        True,\n",
    "        4,\n",
    "        resample=False,\n",
    "    )\n",
    "    negative_samples = SamplingDataset(\n",
    "        train_dataloader,\n",
    "        config,\n",
    "        concern,\n",
    "        num_samples,\n",
    "        False,\n",
    "        4,\n",
    "        resample=False,\n",
    "    )\n",
    "    all_samples = SamplingDataset(\n",
    "        train_dataloader,\n",
    "        config,\n",
    "        200,\n",
    "        num_samples,\n",
    "        False,\n",
    "        4,\n",
    "        resample=False,\n",
    "    )\n",
    "\n",
    "    module = copy.deepcopy(model)\n",
    "\n",
    "    prune_concern_identification(\n",
    "        module,\n",
    "        config,\n",
    "        positive_samples,\n",
    "        negative_samples,\n",
    "        include_layers=[\"intermediate\", \"output\"],\n",
    "        exclude_layers=[\"attention\"],\n",
    "        sparsity_ratio=0.5,\n",
    "        keep_dim=True,\n",
    "        method=\"unstructed\",\n",
    "    )\n",
    "\n",
    "    print(f\"Evaluate the pruned model {concern}\")\n",
    "    result = evaluate_model(module, config, test_dataloader)\n",
    "    result_list.append(result)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.7504</td>\n",
       "      <td>0.6562</td>\n",
       "      <td>0.7001</td>\n",
       "      <td>797</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  class  precision  recall  f1-score  support\n",
       "0     0     0.7504  0.6562    0.7001      797"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.utils.helper import report_to_df, append_nth_row\n",
    "\n",
    "df_list = [report_to_df(df) for df in result_list]\n",
    "new_df = append_nth_row(df_list)\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "decomposetransformer-UESb9BbT-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
