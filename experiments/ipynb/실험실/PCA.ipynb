{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../../../\")\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch\n",
    "from datetime import datetime\n",
    "from src.utils.helper import Config, color_print\n",
    "from src.utils.load import load_model, load_data, save_checkpoint, load_checkpoint\n",
    "from src.models.evaluate import evaluate_model, get_sparsity, get_similarity\n",
    "from src.utils.sampling import SamplingDataset\n",
    "from src.pruning.prune_head import head_importance_prunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"bert-4-128-yahoo\"\n",
    "device = torch.device(\"cuda:0\")\n",
    "checkpoint = None\n",
    "batch_size = 16\n",
    "num_workers = 4\n",
    "num_samples = 128\n",
    "ci_ratio = 0.3\n",
    "seed = 44"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(name, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the model.\n",
      "{'architectures': 'bert',\n",
      " 'dataset_name': 'YahooAnswersTopics',\n",
      " 'model_name': 'models/bert-4-128-yahoo',\n",
      " 'num_labels': 10,\n",
      " 'tokenizer_name': 'fabriceyhc/bert-base-uncased-yahoo_answers_topics'}\n",
      "The model models/bert-4-128-yahoo is loaded.\n"
     ]
    }
   ],
   "source": [
    "model = load_model(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cached dataset YahooAnswersTopics.\n",
      "train.pkl is loaded from cache.\n",
      "valid.pkl is loaded from cache.\n",
      "test.pkl is loaded from cache.\n",
      "The dataset YahooAnswersTopics is loaded\n",
      "{'config_name': 'yahoo_answers_topics',\n",
      " 'features': {'first_column': 'question_title', 'second_column': 'topic'},\n",
      " 'path': 'yahoo_answers_topics'}\n"
     ]
    }
   ],
   "source": [
    "train_dataloader, valid_dataloader, test_dataloader = load_data(\n",
    "    config,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    do_cache=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_samples = SamplingDataset(\n",
    "    train_dataloader,\n",
    "    config,\n",
    "    0,\n",
    "    num_samples,\n",
    "    True,\n",
    "    4,\n",
    "    resample=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_samples = SamplingDataset(\n",
    "    train_dataloader,\n",
    "    config,\n",
    "    0,\n",
    "    num_samples,\n",
    "    False,\n",
    "    4,\n",
    "    resample=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from scipy.stats import norm\n",
    "from typing import *\n",
    "from torch import Tensor\n",
    "from torch.nn import Module\n",
    "import torch.nn.functional as F\n",
    "from functools import partial\n",
    "from src.utils.sampling import SamplingDataset\n",
    "from src.pruning.propagate import propagate\n",
    "from src.utils.helper import Config\n",
    "import gc\n",
    "\n",
    "\n",
    "class Methods:\n",
    "    def __init__(self, ratio: float, axis: int = 0) -> None:\n",
    "        self.ratio = ratio\n",
    "        self.axis = axis\n",
    "        self.coefficient = None\n",
    "\n",
    "    def ci(self, layer, inputs, outputs):\n",
    "        current_weight = layer.weight.data\n",
    "        importance_score = torch.abs(current_weight) * torch.abs(self.coefficient)\n",
    "\n",
    "        W_mask = torch.zeros_like(importance_score) == 1\n",
    "        sort_res = torch.sort(importance_score, dim=self.axis, stable=True)\n",
    "\n",
    "        num_prune = int(importance_score.shape[self.axis] * self.ratio)\n",
    "\n",
    "        if self.axis == 0:\n",
    "            indices_to_prune = sort_res[1][:num_prune, :]\n",
    "        else:\n",
    "            indices_to_prune = sort_res[1][:, :num_prune]\n",
    "        W_mask.scatter_(self.axis, indices_to_prune, True)\n",
    "        current_weight[W_mask] = 0\n",
    "\n",
    "\n",
    "def find_layers(\n",
    "    model: Module,\n",
    "    layer_types: Optional[List[Type[Module]]] = None,\n",
    "    include_layers: Optional[List[str]] = None,\n",
    "    exclude_layers: Optional[List[str]] = None,\n",
    "    prefix: str = \"\",\n",
    ") -> Dict[str, Module]:\n",
    "    if layer_types is None:\n",
    "        layer_types = [nn.Linear]\n",
    "    if include_layers is None:\n",
    "        include_layers = []\n",
    "    if exclude_layers is None:\n",
    "        exclude_layers = []\n",
    "    layers_dict: Dict[str, Module] = {}\n",
    "\n",
    "    def recursive_find(module: Module, prefix: str) -> None:\n",
    "        for name, layer in module.named_children():\n",
    "            layer_name = f\"{prefix}.{name}\" if prefix else name\n",
    "            if any(exclude in layer_name for exclude in exclude_layers):\n",
    "                continue\n",
    "            if include_layers and not any(\n",
    "                include in layer_name for include in include_layers\n",
    "            ):\n",
    "                if not any(isinstance(layer, t) for t in layer_types):\n",
    "                    recursive_find(layer, layer_name)\n",
    "                continue\n",
    "            if isinstance(layer, tuple(layer_types)):\n",
    "                layers_dict[layer_name] = layer\n",
    "            else:\n",
    "                recursive_find(layer, layer_name)\n",
    "\n",
    "    recursive_find(model, prefix)\n",
    "\n",
    "    return layers_dict\n",
    "\n",
    "\n",
    "def get_hook(method):\n",
    "    def hook(module, input, output):\n",
    "        method(module, input, output)\n",
    "\n",
    "    return hook\n",
    "\n",
    "\n",
    "def get_embeddings(model, dataloader):\n",
    "    embeddings_list = {\"embeddings\": [], \"labels\": [], \"attention_mask\": []}\n",
    "\n",
    "    for batch in dataloader:\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        labels = batch[\"labels\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        with torch.no_grad():\n",
    "            input_embeddings = model.get_input_embeddings()(input_ids)\n",
    "        embeddings_list[\"embeddings\"].append(input_embeddings)\n",
    "        embeddings_list[\"labels\"].append(labels)\n",
    "        embeddings_list[\"attention_mask\"].append(attention_mask)\n",
    "\n",
    "        from src.utils.data_class import CustomEmbeddingDataset\n",
    "    return CustomEmbeddingDataset(embeddings_list)\n",
    "\n",
    "\n",
    "def prune_concern_identification(\n",
    "    model: Module,\n",
    "    config: Config,\n",
    "    dominant_concern: SamplingDataset,\n",
    "    non_dominant_concern: SamplingDataset,\n",
    "    sparsity_ratio: float = 0.6,\n",
    "    include_layers: Optional[List[str]] = None,\n",
    "    exclude_layers: Optional[List[str]] = None,\n",
    ") -> None:\n",
    "    layers = find_layers(\n",
    "        model, include_layers=include_layers, exclude_layers=exclude_layers\n",
    "    )\n",
    "    handle_list = []\n",
    "\n",
    "    method1 = Methods(sparsity_ratio, axis=0)\n",
    "    method2 = Methods(sparsity_ratio, axis=1)\n",
    "\n",
    "    for name, layer in layers.items():\n",
    "        if \"intermediate\" in name:\n",
    "            handle = layer.register_forward_hook(method1.ci)\n",
    "        else:\n",
    "            handle = layer.register_forward_hook(method2.ci)\n",
    "        handle_list.append(handle)\n",
    "\n",
    "    pos_embeddings = get_embeddings(model, dominant_concern)\n",
    "    neg_embeddings = get_embeddings(model, non_dominant_concern)\n",
    "    dominant_batches = list(pos_embeddings)\n",
    "    non_dominant_batches = list(neg_embeddings)\n",
    "    combined_batches = {}\n",
    "    keys = dominant_batches[0].keys()\n",
    "    for key in keys:\n",
    "        combined_batches[key] = torch.cat(\n",
    "            [batch[key] for batch in dominant_batches + non_dominant_batches]\n",
    "        )\n",
    "\n",
    "    combined_dataloader = [combined_batches]\n",
    "    method1.coefficient = calc_coefficient(combined_dataloader, dim=0).to(config.device)\n",
    "    print(method1.coefficient)\n",
    "    method2.coefficient = calc_coefficient(combined_dataloader, dim=1).to(config.device)\n",
    "    print(method2.coefficient)\n",
    "    propagate(model, combined_dataloader, config)\n",
    "\n",
    "    for handle in handle_list:\n",
    "        handle.remove()\n",
    "\n",
    "\n",
    "def calc_coefficient(combined_dataloader, dim=0):\n",
    "    X = combined_dataloader[0][\"embeddings\"]\n",
    "\n",
    "    batch_size = X.shape[0] // 2\n",
    "    concern_inputs, non_concern_inputs = (\n",
    "        X[:batch_size],\n",
    "        X[batch_size:],\n",
    "    )\n",
    "\n",
    "    calc_norm = lambda tensors, dim: torch.norm(\n",
    "        tensors.reshape((-1, tensors.shape[-1])), dim=dim\n",
    "    )\n",
    "\n",
    "    if dim == 0:\n",
    "        new_shape = (1, -1)\n",
    "    else:\n",
    "        new_shape = (-1, 1)\n",
    "    concern_norm = calc_norm(concern_inputs, dim=0).reshape(new_shape)\n",
    "    non_concern_norm = calc_norm(non_concern_inputs, dim=0).reshape(new_shape)\n",
    "\n",
    "    cosine_similarity = F.cosine_similarity(\n",
    "        concern_inputs.reshape((-1, concern_inputs.shape[-1])),\n",
    "        non_concern_inputs.reshape((-1, non_concern_inputs.shape[-1])),\n",
    "        dim=0,\n",
    "    ).reshape(new_shape)\n",
    "\n",
    "    sine_similarity = torch.sign(cosine_similarity) * torch.sqrt(\n",
    "        1 - cosine_similarity**2\n",
    "    )\n",
    "    euclidean_distance = torch.sqrt(concern_norm**2 + non_concern_norm**2)\n",
    "    coefficient = (\n",
    "        concern_norm\n",
    "        + sine_similarity\n",
    "        * torch.abs(concern_norm + non_concern_norm)\n",
    "        / euclidean_distance\n",
    "    )\n",
    "    return coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dominant_embeddings = get_embeddings(model, positive_samples)\n",
    "non_dominant_embeddings = get_embeddings(model, negative_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def pca(X, n_components=2):\n",
    "    \"\"\"\n",
    "    주성분 분석(PCA)을 수행하는 함수.\n",
    "\n",
    "    Parameters:\n",
    "    - X: 입력 데이터 행렬 (샘플 수 x 피처 수)\n",
    "    - n_components: 추출할 주성분의 개수\n",
    "\n",
    "    Returns:\n",
    "    - X_pca: 주성분으로 변환된 데이터\n",
    "    - explained_variance: 각 주성분의 설명된 분산 비율\n",
    "    \"\"\"\n",
    "    # Step 1: 데이터 중심화\n",
    "    X_mean = np.mean(X, axis=0)\n",
    "    X_centered = X - X_mean\n",
    "\n",
    "    # Step 2: 공분산 행렬 계산\n",
    "    covariance_matrix = np.cov(X_centered, rowvar=False)\n",
    "\n",
    "    # Step 3: 고유값 및 고유벡터 계산 (고유값 분해)\n",
    "    eigenvalues, eigenvectors = np.linalg.eigh(covariance_matrix)\n",
    "\n",
    "    # 고유값을 내림차순으로 정렬하고, 그에 맞게 고유벡터도 정렬\n",
    "    sorted_indices = np.argsort(eigenvalues)[::-1]\n",
    "    sorted_eigenvalues = eigenvalues[sorted_indices]\n",
    "    sorted_eigenvectors = eigenvectors[:, sorted_indices]\n",
    "\n",
    "    # Step 4: 주성분 선택 (상위 n_components 개수만큼)\n",
    "    selected_eigenvectors = sorted_eigenvectors[:, :n_components]\n",
    "\n",
    "    # Step 5: 데이터 변환 (주성분 축으로)\n",
    "    X_pca = np.dot(X_centered, selected_eigenvectors)\n",
    "\n",
    "    # 설명된 분산 비율 계산\n",
    "    explained_variance = sorted_eigenvalues / np.sum(sorted_eigenvalues)\n",
    "\n",
    "    return X_pca, explained_variance[:n_components]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embeddings': tensor([[[ 0.0276,  0.0207,  0.0063,  ...,  0.0008,  0.0820, -0.0162],\n",
      "         [ 0.0156,  0.0078,  0.0037,  ...,  0.0462, -0.0004,  0.0003],\n",
      "         [ 0.0010,  0.0036,  0.0041,  ..., -0.0162, -0.0136, -0.0167],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0276,  0.0207,  0.0063,  ...,  0.0008,  0.0820, -0.0162],\n",
      "         [ 0.0292,  0.0436,  0.0439,  ...,  0.0255,  0.0244,  0.0213],\n",
      "         [ 0.0182, -0.0137,  0.0317,  ...,  0.0715,  0.0414, -0.0087],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0276,  0.0207,  0.0063,  ...,  0.0008,  0.0820, -0.0162],\n",
      "         [ 0.0300, -0.0336, -0.0220,  ...,  0.0081,  0.0097,  0.0139],\n",
      "         [-0.0018, -0.0033, -0.0157,  ...,  0.0124,  0.0003,  0.0170],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0276,  0.0207,  0.0063,  ...,  0.0008,  0.0820, -0.0162],\n",
      "         [-0.0786,  0.0388, -0.0071,  ..., -0.0007,  0.0554,  0.0079],\n",
      "         [ 0.0272, -0.0226, -0.0177,  ..., -0.0009,  0.0300,  0.0173],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]), 'labels': tensor([0, 0, 0, 0]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])}\n"
     ]
    }
   ],
   "source": [
    "for batch in dominant_embeddings:\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X_pca_result, explained_variance \u001b[38;5;241m=\u001b[39m pca(\u001b[43mdominant_embeddings\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43membeddings\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m, n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(X_pca_result)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(explained_variance)\n",
      "File \u001b[0;32m~/DecomposeTransformer/experiments/ipynb/실험실/../../../src/utils/data_class.py:30\u001b[0m, in \u001b[0;36mCustomEmbeddingDataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m---> 30\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43membeddings\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m,\n\u001b[1;32m     31\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m][index],\n\u001b[1;32m     32\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m, [\u001b[38;5;28;01mNone\u001b[39;00m])[index],\n\u001b[1;32m     33\u001b[0m     }\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "X_pca_result, explained_variance = pca(dominant_embeddings, n_components=2)\n",
    "print(X_pca_result)\n",
    "print(explained_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.7498,  2.6586,  2.5813,  2.4375,  2.4847,  2.5719,  2.9446,  2.6361,\n",
      "          3.3812,  2.5169,  2.6274,  2.6549,  2.9706,  2.6312,  2.6641,  2.6347,\n",
      "          2.7622,  2.7244,  2.8207,  2.5725,  2.5118,  2.5975,  2.5501,  2.8830,\n",
      "          3.1511,  2.7206,  2.5714,  2.4353,  2.5364,  2.5585,  2.8917,  2.4120,\n",
      "          2.6312,  2.6279,  2.5553,  2.5716,  2.6944,  2.6097,  2.6364,  2.4436,\n",
      "          2.6042,  2.9986,  2.6202,  2.5144,  2.7494,  2.6859,  2.9495,  2.6391,\n",
      "          2.6282,  2.6818,  2.7705,  2.6175,  2.5933,  2.8102,  2.4410,  2.7559,\n",
      "          2.5457,  2.7021,  2.7265,  2.6974,  2.9685, -0.2956,  2.7330,  2.4625,\n",
      "          2.9124,  2.8119,  2.8760,  2.6163,  2.4981, -0.3212,  2.8910,  2.5707,\n",
      "          2.6873,  2.5257,  2.6587,  2.5876,  2.5620,  2.5683,  2.5285,  2.6468,\n",
      "          2.7260,  2.5209, -0.3453,  2.4982,  2.9877,  2.4951,  2.6440,  2.8882,\n",
      "          2.6748,  3.1047,  2.5927,  2.8648,  2.5715,  2.4317,  3.5274,  2.6261,\n",
      "          2.6560,  2.6035,  2.6584,  2.8334,  2.9152,  2.6412,  2.6428,  2.5600,\n",
      "          2.5005,  2.4974,  2.9241,  2.5106,  2.7779,  2.5409,  2.5712,  2.5100,\n",
      "          2.6761,  2.8314,  2.4001,  2.5628,  2.5690,  2.7186,  2.7449,  2.4617,\n",
      "          2.7699,  2.4604,  2.6022,  2.6742,  2.9440,  3.0075,  2.6643,  2.8963]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 2.7498],\n",
      "        [ 2.6586],\n",
      "        [ 2.5813],\n",
      "        [ 2.4375],\n",
      "        [ 2.4847],\n",
      "        [ 2.5719],\n",
      "        [ 2.9446],\n",
      "        [ 2.6361],\n",
      "        [ 3.3812],\n",
      "        [ 2.5169],\n",
      "        [ 2.6274],\n",
      "        [ 2.6549],\n",
      "        [ 2.9706],\n",
      "        [ 2.6312],\n",
      "        [ 2.6641],\n",
      "        [ 2.6347],\n",
      "        [ 2.7622],\n",
      "        [ 2.7244],\n",
      "        [ 2.8207],\n",
      "        [ 2.5725],\n",
      "        [ 2.5118],\n",
      "        [ 2.5975],\n",
      "        [ 2.5501],\n",
      "        [ 2.8830],\n",
      "        [ 3.1511],\n",
      "        [ 2.7206],\n",
      "        [ 2.5714],\n",
      "        [ 2.4353],\n",
      "        [ 2.5364],\n",
      "        [ 2.5585],\n",
      "        [ 2.8917],\n",
      "        [ 2.4120],\n",
      "        [ 2.6312],\n",
      "        [ 2.6279],\n",
      "        [ 2.5553],\n",
      "        [ 2.5716],\n",
      "        [ 2.6944],\n",
      "        [ 2.6097],\n",
      "        [ 2.6364],\n",
      "        [ 2.4436],\n",
      "        [ 2.6042],\n",
      "        [ 2.9986],\n",
      "        [ 2.6202],\n",
      "        [ 2.5144],\n",
      "        [ 2.7494],\n",
      "        [ 2.6859],\n",
      "        [ 2.9495],\n",
      "        [ 2.6391],\n",
      "        [ 2.6282],\n",
      "        [ 2.6818],\n",
      "        [ 2.7705],\n",
      "        [ 2.6175],\n",
      "        [ 2.5933],\n",
      "        [ 2.8102],\n",
      "        [ 2.4410],\n",
      "        [ 2.7559],\n",
      "        [ 2.5457],\n",
      "        [ 2.7021],\n",
      "        [ 2.7265],\n",
      "        [ 2.6974],\n",
      "        [ 2.9685],\n",
      "        [-0.2956],\n",
      "        [ 2.7330],\n",
      "        [ 2.4625],\n",
      "        [ 2.9124],\n",
      "        [ 2.8119],\n",
      "        [ 2.8760],\n",
      "        [ 2.6163],\n",
      "        [ 2.4981],\n",
      "        [-0.3212],\n",
      "        [ 2.8910],\n",
      "        [ 2.5707],\n",
      "        [ 2.6873],\n",
      "        [ 2.5257],\n",
      "        [ 2.6587],\n",
      "        [ 2.5876],\n",
      "        [ 2.5620],\n",
      "        [ 2.5683],\n",
      "        [ 2.5285],\n",
      "        [ 2.6468],\n",
      "        [ 2.7260],\n",
      "        [ 2.5209],\n",
      "        [-0.3453],\n",
      "        [ 2.4982],\n",
      "        [ 2.9877],\n",
      "        [ 2.4951],\n",
      "        [ 2.6440],\n",
      "        [ 2.8882],\n",
      "        [ 2.6748],\n",
      "        [ 3.1047],\n",
      "        [ 2.5927],\n",
      "        [ 2.8648],\n",
      "        [ 2.5715],\n",
      "        [ 2.4317],\n",
      "        [ 3.5274],\n",
      "        [ 2.6261],\n",
      "        [ 2.6560],\n",
      "        [ 2.6035],\n",
      "        [ 2.6584],\n",
      "        [ 2.8334],\n",
      "        [ 2.9152],\n",
      "        [ 2.6412],\n",
      "        [ 2.6428],\n",
      "        [ 2.5600],\n",
      "        [ 2.5005],\n",
      "        [ 2.4974],\n",
      "        [ 2.9241],\n",
      "        [ 2.5106],\n",
      "        [ 2.7779],\n",
      "        [ 2.5409],\n",
      "        [ 2.5712],\n",
      "        [ 2.5100],\n",
      "        [ 2.6761],\n",
      "        [ 2.8314],\n",
      "        [ 2.4001],\n",
      "        [ 2.5628],\n",
      "        [ 2.5690],\n",
      "        [ 2.7186],\n",
      "        [ 2.7449],\n",
      "        [ 2.4617],\n",
      "        [ 2.7699],\n",
      "        [ 2.4604],\n",
      "        [ 2.6022],\n",
      "        [ 2.6742],\n",
      "        [ 2.9440],\n",
      "        [ 3.0075],\n",
      "        [ 2.6643],\n",
      "        [ 2.8963]], device='cuda:0')\n",
      "Evaluate the pruned model 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb004e84cb4b4f72931a0e1aaaa40cb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating the model:   0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.2224\n",
      "Precision: 0.6499, Recall: 0.6129, F1-Score: 0.6186\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5405    0.4836    0.5105      2992\n",
      "           1     0.6909    0.4766    0.5641      2992\n",
      "           2     0.7030    0.6036    0.6495      3012\n",
      "           3     0.3329    0.6468    0.4396      2998\n",
      "           4     0.7237    0.7753    0.7486      2973\n",
      "           5     0.8502    0.7564    0.8006      3054\n",
      "           6     0.6870    0.4006    0.5061      3003\n",
      "           7     0.6198    0.6398    0.6296      3012\n",
      "           8     0.5890    0.7113    0.6444      2982\n",
      "           9     0.7619    0.6351    0.6928      2982\n",
      "\n",
      "    accuracy                         0.6130     30000\n",
      "   macro avg     0.6499    0.6129    0.6186     30000\n",
      "weighted avg     0.6502    0.6130    0.6188     30000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_list = []\n",
    "\n",
    "for concern in range(config.num_labels):\n",
    "    config.init_seed()\n",
    "    positive_samples = SamplingDataset(\n",
    "        train_dataloader,\n",
    "        config,\n",
    "        concern,\n",
    "        num_samples,\n",
    "        True,\n",
    "        4,\n",
    "        resample=False,\n",
    "    )\n",
    "    negative_samples = SamplingDataset(\n",
    "        train_dataloader,\n",
    "        config,\n",
    "        concern,\n",
    "        num_samples,\n",
    "        False,\n",
    "        4,\n",
    "        resample=False,\n",
    "    )\n",
    "    all_samples = SamplingDataset(\n",
    "        train_dataloader,\n",
    "        config,\n",
    "        200,\n",
    "        num_samples,\n",
    "        False,\n",
    "        4,\n",
    "        resample=False,\n",
    "    )\n",
    "\n",
    "    module = copy.deepcopy(model)\n",
    "\n",
    "    prune_concern_identification(\n",
    "        module,\n",
    "        config,\n",
    "        positive_samples,\n",
    "        negative_samples,\n",
    "        include_layers=[\"intermediate\", \"output\"],\n",
    "        exclude_layers=[\"attention\"],\n",
    "        sparsity_ratio=0.5,\n",
    "    )\n",
    "\n",
    "    print(f\"Evaluate the pruned model {concern}\")\n",
    "    result = evaluate_model(module, config, test_dataloader)\n",
    "    result_list.append(result)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.5405</td>\n",
       "      <td>0.4836</td>\n",
       "      <td>0.5105</td>\n",
       "      <td>2992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  class  precision  recall  f1-score  support\n",
       "0     0     0.5405  0.4836    0.5105     2992"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.utils.helper import report_to_df, append_nth_row\n",
    "\n",
    "df_list = [report_to_df(df) for df in result_list]\n",
    "new_df = append_nth_row(df_list)\n",
    "new_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "decomposetransformer-UESb9BbT-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
