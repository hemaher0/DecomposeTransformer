{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../../../\")\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch\n",
    "from datetime import datetime\n",
    "from src.utils.helper import Config, color_print\n",
    "from src.utils.load import load_model, load_data, save_checkpoint, load_checkpoint\n",
    "from src.models.evaluate import evaluate_model, get_sparsity, get_similarity\n",
    "from src.utils.sampling import SamplingDataset\n",
    "from src.pruning.prune_head import head_importance_prunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name = \"bert-tiny-yahoo\"\n",
    "name = \"bert-4-128-yahoo\"\n",
    "device = torch.device(\"cuda:0\")\n",
    "checkpoint = None\n",
    "batch_size = 16\n",
    "num_workers = 4\n",
    "num_samples = 16\n",
    "ci_ratio = 0.5\n",
    "seed = 44"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(name, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the model.\n",
      "{'architectures': 'bert',\n",
      " 'dataset_name': 'YahooAnswersTopics',\n",
      " 'model_name': 'models/bert-4-128-yahoo',\n",
      " 'num_labels': 10,\n",
      " 'tokenizer_name': 'fabriceyhc/bert-base-uncased-yahoo_answers_topics'}\n",
      "The model models/bert-4-128-yahoo is loaded.\n"
     ]
    }
   ],
   "source": [
    "model = load_model(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cached dataset YahooAnswersTopics.\n",
      "train.pkl is loaded from cache.\n",
      "valid.pkl is loaded from cache.\n",
      "test.pkl is loaded from cache.\n",
      "The dataset YahooAnswersTopics is loaded\n",
      "{'config_name': 'yahoo_answers_topics',\n",
      " 'features': {'first_column': 'question_title', 'second_column': 'topic'},\n",
      " 'path': 'yahoo_answers_topics'}\n"
     ]
    }
   ],
   "source": [
    "train_dataloader, valid_dataloader, test_dataloader = load_data(\n",
    "    config,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    do_cache=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_samples = SamplingDataset(\n",
    "    train_dataloader,\n",
    "    config,\n",
    "    0,\n",
    "    num_samples,\n",
    "    True,\n",
    "    4,\n",
    "    resample=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_samples = SamplingDataset(\n",
    "    train_dataloader,\n",
    "    config,\n",
    "    0,\n",
    "    num_samples,\n",
    "    False,\n",
    "    4,\n",
    "    resample=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from scipy.stats import norm\n",
    "from typing import *\n",
    "from torch import Tensor\n",
    "from torch.nn import Module\n",
    "import torch.nn.functional as F\n",
    "from functools import partial\n",
    "from src.utils.sampling import SamplingDataset\n",
    "from src.pruning.propagate import propagate\n",
    "from src.utils.helper import Config\n",
    "import gc\n",
    "from src.pruning.prune import prune_concern_identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate the pruned model 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1288a98cdcb4af0b484318d7233fef8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating the model:   0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.2143\n",
      "Precision: 0.6435, Recall: 0.6156, F1-Score: 0.6189\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5123    0.5080    0.5102      2992\n",
      "           1     0.7087    0.4813    0.5732      2992\n",
      "           2     0.7166    0.5920    0.6484      3012\n",
      "           3     0.3570    0.6151    0.4518      2998\n",
      "           4     0.7222    0.7679    0.7444      2973\n",
      "           5     0.8380    0.7639    0.7992      3054\n",
      "           6     0.6700    0.4016    0.5022      3003\n",
      "           7     0.6073    0.6398    0.6231      3012\n",
      "           8     0.5873    0.7207    0.6472      2982\n",
      "           9     0.7160    0.6653    0.6897      2982\n",
      "\n",
      "    accuracy                         0.6156     30000\n",
      "   macro avg     0.6435    0.6156    0.6189     30000\n",
      "weighted avg     0.6439    0.6156    0.6191     30000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_list = []\n",
    "\n",
    "for concern in range(config.num_labels):\n",
    "    config.init_seed()\n",
    "    positive_samples = SamplingDataset(\n",
    "        train_dataloader,\n",
    "        config,\n",
    "        concern,\n",
    "        num_samples,\n",
    "        True,\n",
    "        4,\n",
    "        resample=False,\n",
    "    )\n",
    "    negative_samples = SamplingDataset(\n",
    "        train_dataloader,\n",
    "        config,\n",
    "        concern,\n",
    "        num_samples,\n",
    "        False,\n",
    "        4,\n",
    "        resample=False,\n",
    "    )\n",
    "    all_samples = SamplingDataset(\n",
    "        train_dataloader,\n",
    "        config,\n",
    "        200,\n",
    "        num_samples,\n",
    "        False,\n",
    "        4,\n",
    "        resample=False,\n",
    "    )\n",
    "\n",
    "    module = copy.deepcopy(model)\n",
    "\n",
    "    prune_concern_identification(\n",
    "        module,\n",
    "        config,\n",
    "        positive_samples,\n",
    "        negative_samples,\n",
    "        include_layers=[\"intermediate\", \"output\"],\n",
    "        exclude_layers=[\"attention\"],\n",
    "        sparsity_ratio=ci_ratio,\n",
    "        keep_dim=True,\n",
    "        method=\"structed\",\n",
    "    )\n",
    "\n",
    "    print(f\"Evaluate the pruned model {concern}\")\n",
    "    result = evaluate_model(module, config, test_dataloader)\n",
    "    result_list.append(result)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.5123</td>\n",
       "      <td>0.508</td>\n",
       "      <td>0.5102</td>\n",
       "      <td>2992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  class  precision  recall  f1-score  support\n",
       "0     0     0.5123   0.508    0.5102     2992"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.utils.helper import report_to_df, append_nth_row\n",
    "\n",
    "df_list = [report_to_df(df) for df in result_list]\n",
    "new_df = append_nth_row(df_list)\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "decomposetransformer-UESb9BbT-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
